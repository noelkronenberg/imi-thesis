{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corr_utils.covariate as utils\n",
    "import corr_utils.analysis as analysis_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from stepmix import StepMix\n",
    "from stepmix.bootstrap import blrt_sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(utils)\n",
    "reload(analysis_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'n_components': [1, 2, 3, 4, 5, 6], # number of latent classes\n",
    "    'n_steps' : [1] # number of steps in the estimation (see: https://stepmix.readthedocs.io/en/latest/api.html#stepmix)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_mpl_table(data, col_width=3.0, row_height=0.625, font_size=14,\n",
    "                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='w',\n",
    "                     bbox=[0, 0, 1, 1], header_columns=0,\n",
    "                     ax=None, **kwargs):\n",
    "    if ax is None:\n",
    "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
    "        fig, ax = plt.subplots(figsize=size)\n",
    "        ax.axis('off')\n",
    "\n",
    "    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n",
    "\n",
    "    mpl_table.auto_set_font_size(False)\n",
    "    mpl_table.set_fontsize(font_size)\n",
    "\n",
    "    for k, cell in  six.iteritems(mpl_table._cells):\n",
    "        cell.set_edgecolor(edge_color)\n",
    "        if k[0] == 0 or k[1] < header_columns:\n",
    "            cell.set_text_props(weight='bold', color='w')\n",
    "            cell.set_facecolor(header_color)\n",
    "        else:\n",
    "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
    "    return ax\n",
    "\n",
    "# reference: https://stackoverflow.com/a/39358722"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisistion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns needed\n",
    "\n",
    "base_columns = ['case_id', 'age_during_op', 'female_sex']\n",
    "\n",
    "elixhauser_score_columns = ['elixhauser_van_walraven']\n",
    "\n",
    "original_elixhauser_category_columns = ['aids/hiv_elixhauser', 'alcohol_abuse_elixhauser',\n",
    "'blood_loss_anemia_elixhauser', 'cardiac_arrhythmias_elixhauser',\n",
    "'chronic_pulmonary_disease_elixhauser', 'coagulopathy_elixhauser',\n",
    "'congestive_heart_failure_elixhauser', 'deficiency_anemia_elixhauser',\n",
    "'depression_elixhauser', 'diabetes_complicated_elixhauser',\n",
    "'diabetes_uncomplicated_elixhauser', 'drug_abuse_elixhauser',\n",
    "'fluid_and_electrolyte_disorders_elixhauser',\n",
    "'hypertension_complicated_elixhauser',\n",
    "'hypertension_uncomplicated_elixhauser', 'hypothyroidism_elixhauser',\n",
    "'liver_disease_elixhauser', 'lymphoma_elixhauser',\n",
    "'metastatic_cancer_elixhauser', 'obesity_elixhauser',\n",
    "'other_neurological_disorders_elixhauser', 'paralysis_elixhauser',\n",
    "'peptic_ulcer_disease_excluding_bleeding_elixhauser',\n",
    "'peripheral_vascular_disorders_elixhauser', 'psychoses_elixhauser',\n",
    "'pulmonary_circulation_disorders_elixhauser',\n",
    "'renal_failure_elixhauser',\n",
    "'rheumatoid_arthritis/collagen_vascular_diseases_elixhauser',\n",
    "'solid_tumor_without_metastasis_elixhauser',\n",
    "'valvular_disease_elixhauser', 'weight_loss_elixhauser']\n",
    "\n",
    "elixhauser_outcome_column = ['in_hospital_death']\n",
    "\n",
    "exclusion_column = ['asa_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get (final) study cohort\n",
    "df_elixhauser = pd.read_csv('data/subphenotypes/subphenotypes_cohort_data.csv', delimiter = ',', usecols = base_columns + elixhauser_score_columns + original_elixhauser_category_columns + elixhauser_outcome_column + exclusion_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(df_original:pd.DataFrame):\n",
    "\n",
    "    df = df_original.copy()\n",
    "\n",
    "    rename_dict = {col: col.replace('_elixhauser', '').replace('_', ' ') for col in original_elixhauser_category_columns}\n",
    "    df = df.rename(columns=rename_dict)\n",
    "    elixhauser_category_columns_cleaned = [col.replace('_elixhauser', '').replace('_', ' ') for col in original_elixhauser_category_columns]\n",
    "\n",
    "    rename_dict = {\n",
    "        'aids/hiv': 'HIV Kat. C',\n",
    "        'alcohol abuse': 'Alkoholabusus',\n",
    "        'blood loss anemia': 'Blutungsanämie',\n",
    "        'cardiac arrhythmias': 'HRST',\n",
    "        'chronic pulmonary disease': 'ChronLungenE',\n",
    "        'coagulopathy': 'Gerinnungsstörungen',\n",
    "        'congestive heart failure': 'CHF',\n",
    "        'deficiency anemia': 'Mangelanämie',\n",
    "        'depression': 'Depression',\n",
    "        'diabetes complicated': 'DM, kompliziert',\n",
    "        'diabetes uncomplicated': 'DM, unkompliziert',\n",
    "        'drug abuse': 'Drogenabusus',\n",
    "        'fluid and electrolyte disorders': 'Elytstörung',\n",
    "        'hypertension complicated': 'Hypertonus, kompliziert',\n",
    "        'hypertension uncomplicated': 'Hypertonus, unkompliziert',\n",
    "        'hypothyroidism': 'Hypothyr.',\n",
    "        'liver disease': 'LeberE',\n",
    "        'lymphoma': 'Lymphom',\n",
    "        'metastatic cancer': 'Metastasen',\n",
    "        'obesity': 'Adipositas',\n",
    "        'other neurological disorders': 'Neuro, andere',\n",
    "        'paralysis': 'Lähmung',\n",
    "        'peptic ulcer disease excluding bleeding': 'PU',\n",
    "        'peripheral vascular disorders': 'pAVK',\n",
    "        'psychoses': 'Psychosen',\n",
    "        'pulmonary circulation disorders': 'PulmCircE',\n",
    "        'renal failure': 'Niereninsuffizienz',\n",
    "        'rheumatoid arthritis/collagen vascular diseases': 'RA/KVE',\n",
    "        'solid tumor without metastasis': 'M0',\n",
    "        'valvular disease': 'HKE',\n",
    "        'weight loss': 'Gewichtsverlust'\n",
    "    } \n",
    "\n",
    "    rename_dict_english = {\n",
    "    'aids/hiv': 'HIV Cat. C',\n",
    "    'alcohol abuse': 'AlcoholAbuse',\n",
    "    'blood loss anemia': 'AnemiaBL',\n",
    "    'cardiac arrhythmias': 'Arrhythmia',\n",
    "    'chronic pulmonary disease': 'ChronicLungDis',\n",
    "    'coagulopathy': 'Coagulopathy',\n",
    "    'congestive heart failure': 'CHF',\n",
    "    'deficiency anemia': 'DefAnemia',\n",
    "    'depression': 'Depression',\n",
    "    'diabetes complicated': 'DM, Comp',\n",
    "    'diabetes uncomplicated': 'DM, Uncomp',\n",
    "    'drug abuse': 'DrugAbuse',\n",
    "    'fluid and electrolyte disorders': 'ElectrolyteDis',\n",
    "    'hypertension complicated': 'HTN, Comp',\n",
    "    'hypertension uncomplicated': 'HTN, Uncomp',\n",
    "    'hypothyroidism': 'Hypothyroidism',\n",
    "    'liver disease': 'LiverDis',\n",
    "    'lymphoma': 'Lymphoma',\n",
    "    'metastatic cancer': 'MetastaticCa',\n",
    "    'obesity': 'Obesity',\n",
    "    'other neurological disorders': 'OtherNeuro',\n",
    "    'paralysis': 'Paralysis',\n",
    "    'peptic ulcer disease excluding bleeding': 'PUD',\n",
    "    'peripheral vascular disorders': 'PVD',\n",
    "    'psychoses': 'Psychoses',\n",
    "    'pulmonary circulation disorders': 'PulmCircDis',\n",
    "    'renal failure': 'RenalFail',\n",
    "    'rheumatoid arthritis/collagen vascular diseases': 'RA/CVD',\n",
    "    'solid tumor without metastasis': 'SolidTumor',\n",
    "    'valvular disease': 'ValveDis',\n",
    "    'weight loss': 'WeightLoss'\n",
    "    }\n",
    "    \n",
    "    rename_dict = rename_dict_english\n",
    "\n",
    "    df = df.rename(columns=rename_dict)\n",
    "    elixhauser_category_columns_cleaned = [rename_dict.get(col) for col in elixhauser_category_columns_cleaned]\n",
    "\n",
    "    return df, elixhauser_category_columns_cleaned\n",
    "\n",
    "df_elixhauser, elixhauser_category_columns = clean_names(df_elixhauser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_elixhauser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elixhauser['asa_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import operator\n",
    "df_elixhauser = utils.exclude_rows(df_elixhauser, 'asa_status', [4.0], operator.gt) # NOTE: will also remove NaNs \n",
    "df_elixhauser.reset_index(inplace=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_elixhauser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore data quality\n",
    "utils.get_eda_metrics(df_elixhauser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splot data for analysis\n",
    "X = df_elixhauser[elixhauser_category_columns].copy()\n",
    "Y = df_elixhauser[elixhauser_outcome_column].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search (LCA Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gs(grid):\n",
    "    # base model\n",
    "    model = StepMix(n_components=3, n_steps=1, measurement='bernoulli', structural='bernoulli', random_state=42)\n",
    "\n",
    "    gs = GridSearchCV(estimator=model, cv=3, param_grid=grid)\n",
    "    gs.fit(X, Y)\n",
    "\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = run_gs(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gs(gs, grid):\n",
    "\n",
    "    # log likelihood\n",
    "    results = pd.DataFrame(gs.cv_results_)\n",
    "    results['Val. Log Likelihood'] = results['mean_test_score']\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.lineplot(data=results, x='param_n_components', y='Val. Log Likelihood', hue='param_n_steps', palette='Dark2')\n",
    "\n",
    "    # other metrics (run all models (again) and save parameters)\n",
    "\n",
    "    bic_values = []\n",
    "    sabic_values = []\n",
    "    entropy_values = []\n",
    "    ns_patients = []\n",
    "\n",
    "    for i in range(len(results['params'])):\n",
    "\n",
    "        params = results['params'][i]\n",
    "        current_model = gs.estimator.set_params(**params)\n",
    "        current_model.fit(X,Y)\n",
    "        \n",
    "        bic = current_model.bic(X, Y)\n",
    "        sabic = current_model.sabic(X, Y)\n",
    "        entropy = current_model.relative_entropy(X, Y)\n",
    "        \n",
    "        bic_values.append(bic)\n",
    "        sabic_values.append(sabic)\n",
    "        entropy_values.append(entropy)\n",
    "\n",
    "        # smallest class (n_patients)\n",
    "        array_predictios = current_model.predict(X,Y)\n",
    "        df_predictions = pd.DataFrame(array_predictios, columns=['class'])\n",
    "        assigned_classes_patients = pd.merge(df_elixhauser, df_predictions, left_index=True, right_index=True)\n",
    "        # assigned_classes_patients = get_assigned_classes_patients(current_model)\n",
    "        patient_counts = assigned_classes_patients['class'].value_counts().to_dict()\n",
    "\n",
    "        if patient_counts != {}:\n",
    "            smallest_class = min(patient_counts, key=patient_counts.get)\n",
    "            ns_patients.append(patient_counts.get(smallest_class))\n",
    "        else:\n",
    "            print(f'Skipping smallest_class for {i}')\n",
    "\n",
    "        # smallest probability\n",
    "        # array_proba = current_model.predict_proba(X,Y)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(grid['n_components'], bic_values)\n",
    "    plt.xticks(grid['n_components'])\n",
    "    plt.xlabel('Number of Latent Classes')\n",
    "    plt.ylabel('BIC')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(grid['n_components'], sabic_values)\n",
    "    plt.xticks(grid['n_components'])\n",
    "    plt.xlabel('Number of Latent Classes')\n",
    "    plt.ylabel('SABIC')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(grid['n_components'], entropy_values)\n",
    "    plt.xticks(grid['n_components'])\n",
    "    plt.xlabel('Number of Latent Classes')\n",
    "    plt.ylabel('Scaled Relative Entropy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    if len(ns_patients) != 0:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(grid['n_components'], ns_patients)\n",
    "        plt.xticks(grid['n_components'])\n",
    "        plt.xlabel('Number of Latent Classes')\n",
    "        plt.ylabel('Cases in Smallest Class')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f'Skipping ns_patients for {i}')\n",
    "\n",
    "    df_summary = pd.DataFrame({\n",
    "        'Number of Latent Classes': grid['n_components'],\n",
    "        'BIC': bic_values,\n",
    "        'SABIC': sabic_values,\n",
    "        'Relative Entropy': entropy_values,\n",
    "        'Cases in Smallest Class': ns_patients\n",
    "    })\n",
    "\n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = evaluate_gs(gs, grid)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_mpl_table(df_summary, col_width=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLRT (LCA Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "# model = StepMix(n_components=3, n_steps=1, measurement='bernoulli', structural='bernoulli', random_state=42, verbose=0, progress_bar=0)\n",
    "# p_values = blrt_sweep(model, X, Y, low=grid['n_components'][0], high=grid['n_components'][-1], n_repetitions=2) # n_repetitions for actual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_values < .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_classes, gs=None):\n",
    "\n",
    "    # if grid search results are included, extract data from there\n",
    "    if gs:\n",
    "        results = pd.DataFrame(gs.cv_results_)\n",
    "        results['params'][n_classes-1]\n",
    "        selected_params = results['params'][n_classes-1]\n",
    "        selected_model = gs.estimator.set_params(**selected_params) \n",
    "        \n",
    "    else:\n",
    "        selected_model = StepMix(n_components=n_classes, n_steps=1, measurement='bernoulli', structural='bernoulli', random_state=42)\n",
    "    \n",
    "    selected_model.fit(X,Y)\n",
    "\n",
    "    # selected_model.get_params()\n",
    "    # selected_model.report(X, Y)\n",
    "\n",
    "    return selected_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incidence_probabilities(model):\n",
    "    array_predictios = model.predict(X,Y)\n",
    "    df_predictions = pd.DataFrame(array_predictios, columns=['class'])\n",
    "\n",
    "    df_merged = pd.merge(X, df_predictions, left_index=True, right_index=True)\n",
    "    df_merged['class'] = df_merged['class'] + 1\n",
    "    df_probabilities = df_merged.copy().groupby('class')[elixhauser_category_columns].mean().reset_index()\n",
    "    \n",
    "    # total prevalence\n",
    "    incidences = X[elixhauser_category_columns].sum()\n",
    "    cohort_size = X.shape[0]\n",
    "    total_prevalence = incidences / cohort_size\n",
    "\n",
    "    # class incidences\n",
    "    class_incidences = df_merged.groupby('class')[elixhauser_category_columns].sum()\n",
    "    class_sizes = df_merged['class'].value_counts()\n",
    "\n",
    "    df_normalized_probabilities = df_probabilities.copy()\n",
    "\n",
    "    # class and normalized prevalence\n",
    "    for column in elixhauser_category_columns:\n",
    "            class_prevalence = class_incidences[column] / class_sizes\n",
    "            df_normalized_probabilities[column] = df_probabilities['class'].map(class_prevalence) / total_prevalence[column]\n",
    "    \n",
    "    return df_normalized_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigned Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assigned_classes_patients(model):\n",
    "    array_predictios = model.predict(X,Y)\n",
    "    df_predictions = pd.DataFrame(array_predictios, columns=['class'])\n",
    "    df_predictions['class'] = df_predictions['class'] + 1 # remove 0 indexing\n",
    "    df_merged = pd.merge(df_elixhauser, df_predictions, left_index=True, right_index=True)\n",
    "\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_assigned_classes_patients(models_class_numbers:list):\n",
    "    \n",
    "    list_predictions_dfs = []\n",
    "\n",
    "    for n_classes in models_class_numbers:\n",
    "        model = get_model(n_classes, False)\n",
    "        array_predictions = model.predict(X,Y)\n",
    "        df_predictions = pd.DataFrame(array_predictions, columns=[f'class_{n_classes}'])\n",
    "        df_predictions[f'class_{n_classes}'] = df_predictions[f'class_{n_classes}'] + 1\n",
    "        list_predictions_dfs.append(df_predictions)\n",
    "\n",
    "    df_all_predictions = pd.concat(list_predictions_dfs, axis=1)\n",
    "    df_merged = pd.concat([df_elixhauser, df_all_predictions], axis=1)\n",
    "\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assigned_classes_categories(probabilities):\n",
    "\n",
    "    category_max_values = {}\n",
    "    category_max_classes = {}\n",
    "\n",
    "    for category in elixhauser_category_columns:\n",
    "\n",
    "        # find max value = assigned class\n",
    "        max_value = probabilities[category].max()\n",
    "        max_class = probabilities[probabilities[category] == max_value]['class'].values[0]\n",
    "        category_max_values[category] = max_value\n",
    "        category_max_classes[category] = max_class\n",
    "\n",
    "    df_assigned_class = pd.DataFrame.from_dict({\n",
    "        'Category': list(category_max_values.keys()),\n",
    "        'Highest Value': list(category_max_values.values()),\n",
    "        'Class with Highest Value': [f'{category_max_classes[category]}' for category in category_max_values]\n",
    "    })\n",
    "\n",
    "    return df_assigned_class.sort_values('Class with Highest Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_categories(assigned_classes):\n",
    "    df_class_categories = assigned_classes.groupby('Class with Highest Value')['Category'].apply(list).reset_index()\n",
    "    df_class_categories['Number of Categories'] = df_class_categories['Category'].apply(len)\n",
    "    return df_class_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polar_plot(model, class_order:list):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # helpers for class numbers\n",
    "    probabilities = get_incidence_probabilities(model)\n",
    "    assigned_classes = get_assigned_classes_categories(probabilities)\n",
    "    class_categories = get_class_categories(assigned_classes)\n",
    "    category_count_dict = dict(zip(class_categories['Class with Highest Value'], class_categories['Number of Categories']))\n",
    "\n",
    "    # helper for patient numbers\n",
    "    assigned_classes_patients = get_assigned_classes_patients(model)\n",
    "    patient_counts = assigned_classes_patients['class'].value_counts().to_dict()\n",
    "\n",
    "    # helper for incidence numbers\n",
    "    # incidences = X[elixhauser_category_columns].sum()\n",
    "    # incidence_counts = incidences.sort_values(ascending=False).to_dict()\n",
    "\n",
    "    # helper for category order (NOTE: specific to amount of classes)\n",
    "    cat_one = list(class_categories[class_categories['Class with Highest Value'] == '1']['Category'])\n",
    "    cat_two = list(class_categories[class_categories['Class with Highest Value'] == '2']['Category'])\n",
    "    cat_three = list(class_categories[class_categories['Class with Highest Value'] == '3']['Category'])\n",
    "    cat_four = list(class_categories[class_categories['Class with Highest Value'] == '4']['Category'])\n",
    "    cat_five = list(class_categories[class_categories['Class with Highest Value'] == '5']['Category'])\n",
    "    ordered_categories = cat_one + cat_two + cat_three + cat_four + cat_five\n",
    "    ordered_categories = [\n",
    "        x\n",
    "        for xs in ordered_categories\n",
    "        for x in xs\n",
    "    ]\n",
    "\n",
    "    # sort classes accordingly\n",
    "    class_order_dict = {class_id: index for index, class_id in enumerate(class_order)}\n",
    "    sorted_classes = sorted(probabilities['class'].unique(), key=lambda c: class_order_dict.get(c, float('inf')))\n",
    "    class_rename_dict = {class_id: f'{index + 1}' for index, class_id in enumerate(class_order)}\n",
    "\n",
    "    # graph colors (NOTE: specific to amount of classes)\n",
    "\n",
    "    colors = {\n",
    "            '1': 'rgba(137, 146, 251, 0.1)', \n",
    "            '2': 'rgba(241, 108, 86, 0.1)',    \n",
    "            '3': 'rgba(114, 219, 197, 0.1)',   \n",
    "            '4': 'rgba(200, 166, 247, 0.1)',  \n",
    "            '5': 'rgba(251, 170, 109, 0.1)'    \n",
    "    }\n",
    "\n",
    "    line_colors = {\n",
    "            '1': 'rgba(137, 146, 251, 1)', \n",
    "            '2': 'rgba(241, 108, 86, 1)',    \n",
    "            '3': 'rgba(114, 219, 197, 1)',   \n",
    "            '4': 'rgba(200, 166, 247, 1)',  \n",
    "            '5': 'rgba(251, 170, 109, 1)'    \n",
    "    }\n",
    "\n",
    "\n",
    "    # iterate over each class\n",
    "    max_value = 0\n",
    "    for class_label in sorted_classes:\n",
    "        # get class data\n",
    "        class_data = probabilities[probabilities['class'] == class_label]\n",
    "        values = class_data[ordered_categories].values.flatten() \n",
    "        categories = ordered_categories\n",
    "        max_value = max(max_value, max(values))\n",
    "\n",
    "        # helper for class numbers\n",
    "        n_categories = category_count_dict.get(str(class_label), 0)\n",
    "\n",
    "        # helper for patient numbers\n",
    "        n_patients = patient_counts.get(class_label, 0)\n",
    "\n",
    "        # helper for new category labels\n",
    "        # category_labels_with_incidence = [f\"{cat} (cases: {incidence_counts.get(cat, 0)})\" for cat in categories]\n",
    "\n",
    "        renamed_class = class_rename_dict.get(class_label, class_label)\n",
    "\n",
    "        fill_color = colors.get(renamed_class) \n",
    "        line_color = line_colors.get(renamed_class) \n",
    "\n",
    "        # add data to graph\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=values.tolist() + [values[0]],\n",
    "            theta=categories + [categories[0]],\n",
    "            name=f'Cluster {renamed_class} (categories: {n_categories} | cases: {n_patients})',\n",
    "            fill='toself', \n",
    "            fillcolor=fill_color,\n",
    "            line=dict(color=line_color)\n",
    "        ))\n",
    "\n",
    "    # add line at prevalence ? 3\n",
    "    num_categories = len(ordered_categories)\n",
    "    circle_r = [3] * num_categories\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=circle_r + [circle_r[0]], \n",
    "        theta=ordered_categories + [ordered_categories[0]], \n",
    "        mode='lines',\n",
    "        line=dict(color='red', dash='dash'), \n",
    "        name='Prevalence = 3',\n",
    "        showlegend=True\n",
    "    ))\n",
    "\n",
    "    # adjust layout\n",
    "    fig.update_layout(\n",
    "        polar=dict(\n",
    "            radialaxis=dict(\n",
    "                    visible=True,\n",
    "                    showline=True, \n",
    "                    linecolor='rgba(0,0,0,0.1)',\n",
    "                    gridcolor='rgba(0,0,0,0.1)',\n",
    "                    range=[0, max_value]\n",
    "                ),\n",
    "            angularaxis=dict(\n",
    "                tickfont=dict(\n",
    "                    size=24),\n",
    "                linecolor='grey',\n",
    "                gridcolor='rgba(0,0,0,0.1)'\n",
    "            ),\n",
    "            bgcolor='white'\n",
    "        ),\n",
    "        width=2400,\n",
    "        height=1200,\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            font=dict(\n",
    "                size=24\n",
    "            )\n",
    "        ),\n",
    "        paper_bgcolor='rgba(255,255,255)',\n",
    "        plot_bgcolor='rgba(255,255,255)'\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(n_classes):\n",
    "    selected_model = get_model(n_classes)\n",
    "    fig = get_polar_plot(selected_model)\n",
    "    probabilities = get_incidence_probabilities(selected_model)\n",
    "    category_classes = get_assigned_classes_categories(probabilities)\n",
    "    patient_classes = get_assigned_classes_patients(selected_model)\n",
    "    class_categories = get_class_categories(category_classes)\n",
    "\n",
    "    return fig, category_classes, class_categories, patient_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model = get_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = get_incidence_probabilities(selected_model)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_classes = get_assigned_classes_categories(probabilities)\n",
    "category_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_classes_5 = get_assigned_classes_patients(selected_model)\n",
    "class_categories = get_class_categories(category_classes)\n",
    "class_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_order = [5, 3, 4, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_polar_plot(selected_model, class_order)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_elixhauser, patient_classes_5[['case_id', 'class']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged, _ = clean_names(df_merged)\n",
    "rename_dict = {\n",
    "    'age_during_op': 'Alter bei OP', \n",
    "    'female_sex': 'Geschlecht weiblich', \n",
    "    'asa_status': 'ASA Status',\n",
    "    'elixhauser_van_walraven': 'Elixhauser',\n",
    "    'bmi': 'BMI'\n",
    "    }\n",
    "df_merged = df_merged.rename(columns=rename_dict)\n",
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_merged.drop(columns=['pat_id', 'case_id', 'op_length', 'weight', 'height', 'admission_date_time', 'discharge_date_time', 'ops_code', 'op_date_time', 'birth_date', 'op_start_date_time', 'op_end_date_time', 'elixhauser_AHRQ', 'class', 'elevated_risk_surgery', 'MI_history', 'CD_history', 'prior_insulin', 'prior_creatinine', 'vascular_disease_history', 'STT_history', 'AF_history', 'in_hospital_death', 'stroke_30_days', 'MACE_30_days', 'RCRI', 'CHA2DS2_VASc'])\n",
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order classes\n",
    "df_merged['class'] = df_merged['class'].astype(str)\n",
    "class_order_dict = {str(class_id): index + 1 for index, class_id in enumerate(class_order)}\n",
    "df_merged['class'] = df_merged['class'].map(lambda x: class_order_dict.get(x))\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tableone import TableOne\n",
    "\n",
    "data = df_merged\n",
    "\n",
    "columns = df_cleaned.columns.tolist()\n",
    "categorical = df_cleaned.drop(columns=columns).columns.tolist()\n",
    "\n",
    "groupby = 'class'\n",
    "\n",
    "mytable = TableOne(data=data, columns=columns, categorical=categorical, groupby=groupby, pval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view as DF\n",
    "\n",
    "mytable.to_csv('data/subphenotypes/table-one.csv')\n",
    "df_tableOne = pd.read_csv('data/subphenotypes/table-one.csv', delimiter = ',')\n",
    "\n",
    "tableOne_columns = [\n",
    "    '', \n",
    "    '', \n",
    "    'Fehlende',\n",
    "    'Gesamt', \n",
    "    '1',\n",
    "    '2',\n",
    "    '3',\n",
    "    '4',\n",
    "    '5',\n",
    "    'P-Wert'\n",
    "]\n",
    "\n",
    "df_tableOne.columns = tableOne_columns\n",
    "\n",
    "df_tableOne = df_tableOne.drop(index=0)\n",
    "df_tableOne = df_tableOne.reset_index(drop=True)\n",
    "df_tableOne.to_csv('data/subphenotypes/table-one_adj.csv')\n",
    "\n",
    "render_mpl_table(df_tableOne, col_width=5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mytable.tabulate(tablefmt='github'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://stepmix.readthedocs.io/en/latest/index.html\n",
    "- https://colab.research.google.com/drive/1btXHCx90eCsnUlQv_yN-9AzKDhJP_JkG?usp=drive_link#scrollTo=132vQNd8wE3J"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
