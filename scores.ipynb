{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corr_utils\n",
    "import corr_utils.covariate as utils\n",
    "import corr_utils.analysis as analysis_utils\n",
    "import corr_utils.ml as ml_utils\n",
    "import corr_utils.extraction as pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "reload(utils)\n",
    "reload(pipeline)\n",
    "reload(ml_utils)\n",
    "reload(analysis_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_utils.set_default_key(key='case_id') # default key for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, error = pipeline.connect_impala(\n",
    "    remote_hostname='hdl-edge01.charite.de', \n",
    "    username='nokr10'\n",
    "    ) # connect to HDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = None # amount of rows to load (for faster exploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_date = \"CAST( `_hdl_loadstamp` AS DATE) <= '2024-09-05'\" # set for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.2 # split used for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline.disconnect_impala(conn) # disconnect from HDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = (\n",
    "    '(c_var_name = \"Behandlung_OP_Zeiten_Ereignisname\" AND c_value IN (\"BEGAN\", \"FREIG\", \"ENDEL\", \"SCHNI\", \"EINSC\", \"ENDAN\", \"NAHT\", \"BEGAW\")) OR ' # OP times\n",
    "    'c_var_name IN (\"BEH_ANAE_ASA_STATUS\", \"Risiko_ASA\", \"Behandlung_Anae_Praemed_ASA_Status\", \"Praemedikation_ASA_Status\") OR ' # ASA status\n",
    "    'c_var_name IN (\"Patient_Gewicht\", \"Behandlung_Gewicht\", \"Behandlung_Gewicht_Aufnahme\", \"CO_klinStatus_Behandlung_Patient_Aufnahme_Gewicht_\", \"CO_Patient_Aufnahme_Gewicht\") OR ' # weight\n",
    "    'c_var_name IN (\"Patient_Groesse\", \"Praemedikation_Groesse\", \"CO_klinStatus_Behandlung_Patient_Aufnahme_Groesse_\", \"CO_Patient_Aufnahme_Groesse\")' # height\n",
    ")\n",
    "\n",
    "df_hdl_copra_hierarchy = pipeline.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_copra6_hierarchy_v2', \n",
    "    conn=conn, \n",
    "    limit=limit, \n",
    "    where=where + ' AND ' + extraction_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchy = utils.extract_df_data(\n",
    "    df_hdl_copra_hierarchy, \n",
    "    col_dict={\n",
    "        'c_falnr':'case_id', \n",
    "        'c_var_name':'variable', \n",
    "        'c_value':'value', \n",
    "        'c_var_timestamp':'date_time'\n",
    "        },\n",
    "    remove_prefix=False,\n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_hierarchy = df_hierarchy.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'variable': str,\n",
    "    # 'value': ...,\n",
    "})\n",
    "\n",
    "for column in ['date_time']:\n",
    "    df_hierarchy[f'{column}'] = pd.to_datetime(df_hierarchy[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prodecures (nicp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hdl_sap_procedure = pipeline.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_ishmed_procedure', \n",
    "    conn=conn, \n",
    "    limit=limit, \n",
    "    where=extraction_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nicp = utils.extract_df_data(\n",
    "    df_hdl_sap_procedure, \n",
    "    col_dict={\n",
    "        'c_falnr':'case_id', \n",
    "        'c_prozedur_code':'ops_code', \n",
    "        'c_prozedur_begin':'procedure_date_time'\n",
    "        },\n",
    "    remove_prefix=False,\n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_nicp = df_nicp.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'ops_code': str,\n",
    "})\n",
    "\n",
    "for column in ['procedure_date_time']:\n",
    "    df_nicp[f'{column}'] = pd.to_datetime(df_nicp[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nicp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient (npat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hdl_sap_patient = pipeline.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_ishmed_patient', \n",
    "    conn=conn, \n",
    "    limit=limit, \n",
    "    where=extraction_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_npat = utils.extract_df_data(\n",
    "    df_hdl_sap_patient, \n",
    "    col_dict={\n",
    "        'c_falnr':'case_id', \n",
    "        'c_gender':'gender', \n",
    "        'c_birthdate':'birth_date', \n",
    "        'c_datetimeofdeath':'death_date_time'\n",
    "        },\n",
    "    remove_prefix=False,\n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "df_npat = utils.handle_duplicates(\n",
    "    df=df_npat, \n",
    "    column='case_id', \n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_npat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types (for direct processing)\n",
    "df_npat['birth_date'] = pd.to_datetime(df_npat['birth_date'])\n",
    "df_npat['death_date_time'] = pd.to_datetime(df_npat['death_date_time'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add death indicator\n",
    "df_npat['died'] = 0\n",
    "df_npat.loc[df_npat['death_date_time'].notna(), 'died'] = 1\n",
    "df_npat['died'] = df_npat['died'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unknowns (defined as 'Unknown')\n",
    "df_npat = utils.exclude_rows(df=df_npat, column='gender', items=['Unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust format\n",
    "df_npat['female_sex'] = 0\n",
    "df_npat['female_sex'] = (df_npat['gender'] == 'F').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove old column\n",
    "df_npat = df_npat.drop(columns=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_npat = df_npat.astype({\n",
    "    # 'case_id': str,\n",
    "    'female_sex': int,\n",
    "    'died': int\n",
    "})\n",
    "\n",
    "for column in ['birth_date', 'death_date_time']:\n",
    "    df_npat[f'{column}'] = pd.to_datetime(df_npat[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_npat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = (\n",
    "    'c_katalog_leistungtext LIKE \"%Kreatinin%\" AND c_wert <> \"0\"'\n",
    ")\n",
    "\n",
    "df_sap_lab = pipeline.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_ishmed_labor', \n",
    "    conn=conn, \n",
    "    limit=limit, \n",
    "    where=where + ' AND ' + extraction_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab = utils.extract_df_data(\n",
    "    df=df_sap_lab, \n",
    "    col_dict={\n",
    "        'c_falnr':'case_id', \n",
    "        'c_katalog_leistungtext':'substance', \n",
    "        'c_wert':'quantity', \n",
    "        'c_wert_einheit':'unit', \n",
    "        'c_wert_timestamp':'substance_date_time'\n",
    "        },\n",
    "    remove_prefix=False,\n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numeric\n",
    "df_lab['quantity'] = pd.to_numeric(df_lab['quantity'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-numerics\n",
    "df_lab_cleaned = df_lab.dropna(subset=['quantity']) \n",
    "utils.get_amount_removed_rows(\n",
    "    initial=df_lab, \n",
    "    new=df_lab_cleaned\n",
    "    )\n",
    "df_lab = df_lab_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_lab = df_lab.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'substance': str,\n",
    "    'quantity': float,\n",
    "    # 'unit': str,\n",
    "})\n",
    "\n",
    "for column in ['substance_date_time']:\n",
    "    df_lab[f'{column}'] = pd.to_datetime(df_lab[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases (cohort complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hdl_sap_fall = pipeline.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_ishmed_fall', \n",
    "    conn=conn, \n",
    "    limit=limit, \n",
    "    where=extraction_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_complete = utils.extract_df_data(\n",
    "    df=df_hdl_sap_fall, \n",
    "    col_dict={\n",
    "        'c_patnr':'pat_id',\n",
    "        'c_falnr':'case_id', \n",
    "        'c_aufnahme':'admission_date_time', \n",
    "        'c_entlassung':'discharge_date_time'\n",
    "        }, \n",
    "    remove_prefix=False,\n",
    "    drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_cohort_complete = df_cohort_complete.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'pat_id': str\n",
    "})\n",
    "\n",
    "for column in ['admission_date_time', 'discharge_date_time']:\n",
    "    df_cohort_complete[f'{column}'] = pd.to_datetime(df_cohort_complete[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnoses (ndia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hdl_copra_diagnose = pipeline.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_ishmed_diagnose', \n",
    "    conn=conn, \n",
    "    limit=limit, \n",
    "    where=extraction_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ndia = utils.extract_df_data(\n",
    "    df=df_hdl_copra_diagnose, \n",
    "    col_dict={\n",
    "        'c_falnr':'case_id', \n",
    "        'c_diagnose_1':'icd_code', \n",
    "        'c_diagnose_timestamp':'diagnosis_date_time', \n",
    "        'c_gewissheit':'certainty'\n",
    "        }, \n",
    "    remove_prefix=False,\n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude \"Ausgeschlossen\" or \"Verworfen\" (https://health-data.charite.de/data-model/ish-med/ndia/diagw)\n",
    "df_ndia = utils.exclude_rows(\n",
    "    df=df_ndia, \n",
    "    column='certainty', \n",
    "    items=['A', 'VW'], \n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_ndia = df_ndia.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'icd_code': str\n",
    "})\n",
    "\n",
    "for column in ['diagnosis_date_time']:\n",
    "    df_ndia[f'{column}'] = pd.to_datetime(df_ndia[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ndia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = (\n",
    "    \"LOWER(c_generic_name) LIKE '%insulin%'\" # insulin\n",
    ")\n",
    "\n",
    "df_hdl_copra_medication = pipeline.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_copra6_medication', \n",
    "    conn=conn, \n",
    "    limit=limit, \n",
    "    where=where + ' AND ' + extraction_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medication = utils.extract_df_data(\n",
    "    df=df_hdl_copra_medication, \n",
    "    col_dict={\n",
    "        'c_falnr':'case_id', \n",
    "        'c_generic_name':'medication', \n",
    "        'c_application_start':'medication_date_time'\n",
    "        }, \n",
    "    remove_prefix=False,\n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime\n",
    "df_medication['medication_date_time'] = pd.to_datetime(df_medication['medication_date_time'], utc=True) # UTC+1 to UTC\n",
    "df_medication['medication_date_time'] = df_medication['medication_date_time'].dt.strftime('%Y-%m-%d %H:%M:%S') # remove timezone information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_medication = df_medication.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'medication': str,\n",
    "})\n",
    "\n",
    "for column in ['medication_date_time']:\n",
    "    df_medication[f'{column}'] = pd.to_datetime(df_medication[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = (\n",
    "    'c_bewegungsart = \"OP\" AND ' # surgeries\n",
    "    '(c_pflege_oe_id LIKE \"S%\" OR c_pflege_oe_id LIKE \"W%\" OR c_pflege_oe_id LIKE \"M%\")' # information about campus\n",
    "    )\n",
    "\n",
    "df_sap_movement = pipeline.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_ishmed_bewegung', \n",
    "    conn=conn, \n",
    "    limit=limit, \n",
    "    where=where + ' AND ' + extraction_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campi = utils.extract_df_data(\n",
    "    df=df_sap_movement, \n",
    "    col_dict={'c_falnr':'case_id', 'c_pflege_oe_id':'station', 'c_begin':'movement_start_date_time', 'c_ende':'movement_end_date_time'}, \n",
    "    remove_prefix=False,\n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get campus information (first letter)\n",
    "df_campi['campus'] = df_campi['station'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by dates (to ensure earliest are at the top)\n",
    "df_campi = df_campi.sort_values(by='movement_start_date_time', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only first OP (for each case)\n",
    "df_campi = utils.handle_duplicates(\n",
    "    df=df_campi, \n",
    "    column='case_id',\n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove edge cases\n",
    "for column in ['movement_start_date_time', 'movement_end_date_time']:\n",
    "    df_campi_cleaned = df_campi[\n",
    "        (df_campi[column] >= pd.Timestamp.min) &\n",
    "        (df_campi[column] <= pd.Timestamp.max)\n",
    "    ]\n",
    "utils.get_amount_removed_rows(\n",
    "    initial=df_campi, \n",
    "    new=df_campi_cleaned\n",
    "    )\n",
    "df_campi = df_campi_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_campi = df_campi.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'station': str\n",
    "})\n",
    "\n",
    "for column in ['movement_start_date_time', 'movement_end_date_time']:\n",
    "    df_campi[f'{column}'] = pd.to_datetime(df_campi[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cases with OP\n",
    "df_op = utils.extract_df_data(\n",
    "    df=df_nicp, \n",
    "    col_dict={\n",
    "        'procedure_date_time':'op_date_time'\n",
    "        }, \n",
    "    filter_dict={\n",
    "        'ops_code':['^5']\n",
    "        },\n",
    "    drop=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_op = df_op.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'ops_code': str,\n",
    "})\n",
    "\n",
    "for column in ['op_date_time']:\n",
    "    df_op[f'{column}'] = pd.to_datetime(df_op[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing dates\n",
    "df_op = utils.exclude_rows(\n",
    "    df=df_op, \n",
    "    column='op_date_time', \n",
    "    items=[pd.NaT]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by dates (to ensure earliest are at the top)\n",
    "df_cohort_complete = df_cohort_complete.sort_values(by='admission_date_time', ascending=True)\n",
    "df_op = df_op.sort_values(by='op_date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only first OP (for each case)\n",
    "df_op = utils.handle_duplicates(\n",
    "    df=df_op, \n",
    "    column='case_id', \n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep cohort cases with OP\n",
    "df_op_cohort = pd.merge(df_cohort_complete, df_op, on='case_id', how='inner')\n",
    "utils.get_amount_removed_rows(\n",
    "    initial=df_cohort_complete, \n",
    "    new=df_op_cohort\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only first OP for each patient (among cases)\n",
    "df_cohort = utils.handle_duplicates(\n",
    "    df=df_op_cohort, \n",
    "    column='pat_id', \n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing dates\n",
    "df_cohort = utils.exclude_rows(\n",
    "    df=df_cohort, \n",
    "    column='admission_date_time', \n",
    "    items=[pd.NaT]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing dates\n",
    "df_cohort = utils.exclude_rows(\n",
    "    df=df_cohort, \n",
    "    column='discharge_date_time', \n",
    "    items=[pd.NaT]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cases that are outside of stay\n",
    "\n",
    "conditions = [\n",
    "    (lambda row: (row['admission_date_time'] < row['op_date_time']) and (row['op_date_time'] < row['discharge_date_time']), 'OP_between_stay')\n",
    "]\n",
    "\n",
    "df_cohort_cleaned = utils.create_subgroups(\n",
    "    df=df_cohort, \n",
    "    conditions=conditions\n",
    "    )\n",
    "\n",
    "df_cohort_cleaned_removed = utils.exclude_rows(\n",
    "    df=df_cohort_cleaned, \n",
    "    column='OP_between_stay', \n",
    "    items=[0]\n",
    "    )\n",
    "df_cohort_cleaned_removed.drop(columns=['OP_between_stay'], inplace=True)\n",
    "df_cohort = df_cohort_cleaned_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add campi\n",
    "df_cohort = pd.merge(\n",
    "    df_cohort, df_campi[['case_id', 'campus', 'movement_start_date_time', 'movement_end_date_time']], \n",
    "    on='case_id', how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cases with op outside movements\n",
    "\n",
    "conditions = [\n",
    "    (lambda row: (row['movement_start_date_time'] <= row['op_date_time']) and (row['op_date_time'] <= row['movement_end_date_time']), 'movement_between_stay')\n",
    "]\n",
    "\n",
    "df_cohort_cleaned = utils.create_subgroups(\n",
    "    df=df_cohort, \n",
    "    conditions=conditions\n",
    "    )\n",
    "\n",
    "df_cohort_cleaned_removed = utils.exclude_rows(\n",
    "    df=df_cohort_cleaned, \n",
    "    column='movement_between_stay', \n",
    "    items=[0]\n",
    "    )\n",
    "df_cohort_cleaned_removed = df_cohort_cleaned\n",
    "df_cohort_cleaned_removed.drop(columns=['movement_between_stay', 'movement_start_date_time', 'movement_end_date_time'], inplace=True)\n",
    "df_cohort = df_cohort_cleaned_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_cohort = df_cohort.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'pat_id': str,\n",
    "    # 'ops_code': str,\n",
    "    # 'campus': str\n",
    "})\n",
    "\n",
    "for column in ['admission_date_time', 'discharge_date_time', 'op_date_time']:\n",
    "    df_cohort[f'{column}'] = pd.to_datetime(df_cohort[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derived Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep ICDs before OP\n",
    "df_prior_diagnoses = utils.filter_time_between(\n",
    "    df=df_ndia, time_column='diagnosis_date_time', \n",
    "    df_time_reference=df_cohort, \n",
    "    df_time_reference_column_upper_bound='op_date_time', \n",
    "    merge_on='case_id', \n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_prior_diagnoses = df_prior_diagnoses.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'icd_code': str\n",
    "})\n",
    "\n",
    "for column in ['diagnosis_date_time']:\n",
    "    df_prior_diagnoses[f'{column}'] = pd.to_datetime(df_prior_diagnoses[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior_diagnoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior Medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep medications before OP\n",
    "df_prior_medication = utils.filter_time_between(\n",
    "    df=df_medication, time_column='medication_date_time', \n",
    "    df_time_reference=df_cohort, \n",
    "    between=True, \n",
    "    df_time_reference_column_upper_bound='op_date_time', \n",
    "    df_time_reference_column_lower_bound='admission_date_time',\n",
    "    merge_on='case_id', \n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_prior_medication = df_prior_medication.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'medication': str,\n",
    "})\n",
    "\n",
    "for column in ['medication_date_time']:\n",
    "    df_prior_medication[f'{column}'] = pd.to_datetime(df_prior_medication[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior_medication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep labs before OP\n",
    "df_prior_lab = utils.filter_time_between(\n",
    "    df=df_lab, \n",
    "    time_column='substance_date_time', \n",
    "    df_time_reference=df_cohort, \n",
    "    between=True, \n",
    "    df_time_reference_column_upper_bound='op_date_time', \n",
    "    df_time_reference_column_lower_bound='admission_date_time',\n",
    "    merge_on='case_id', \n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_prior_lab = df_prior_lab.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'substance': str,\n",
    "    'quantity': float,\n",
    "    # 'unit': str,\n",
    "})\n",
    "\n",
    "for column in ['substance_date_time']:\n",
    "    df_prior_lab[f'{column}'] = pd.to_datetime(df_prior_lab[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30 days after OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 30 days after OP\n",
    "df_cohort_temp = df_cohort[['case_id', 'op_date_time']].copy()\n",
    "df_cohort_temp['30_days'] = df_cohort['op_date_time'] + pd.Timedelta(days=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnoses 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep ICDs 30 days after OP\n",
    "df_diagnoses_30_days = utils.filter_time_between(\n",
    "    df=df_ndia, \n",
    "    time_column='diagnosis_date_time', \n",
    "    df_time_reference=df_cohort_temp, \n",
    "    between=True,\n",
    "    df_time_reference_column_upper_bound='30_days', \n",
    "    df_time_reference_column_lower_bound='op_date_time', \n",
    "    merge_on='case_id', \n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_diagnoses_30_days = df_diagnoses_30_days.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'icd_code': str\n",
    "})\n",
    "\n",
    "for column in ['diagnosis_date_time']:\n",
    "    df_diagnoses_30_days[f'{column}'] = pd.to_datetime(df_diagnoses_30_days[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnoses_30_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedures 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep OPS 30 days after OP\n",
    "df_procedures_30_days = utils.filter_time_between(\n",
    "    df=df_nicp, \n",
    "    time_column='procedure_date_time', \n",
    "    df_time_reference=df_cohort_temp, \n",
    "    between=True, \n",
    "    df_time_reference_column_upper_bound='30_days', \n",
    "    df_time_reference_column_lower_bound='op_date_time', \n",
    "    merge_on='case_id', \n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_procedures_30_days = df_procedures_30_days.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'ops_code': str\n",
    "})\n",
    "\n",
    "for column in ['procedure_date_time']:\n",
    "    df_procedures_30_days[f'{column}'] = pd.to_datetime(df_procedures_30_days[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedures_30_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables (Basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add given variables to cohort\n",
    "df_cohort = pd.merge(\n",
    "    df_cohort, df_npat[['case_id', 'female_sex', 'birth_date']],\n",
    "    on='case_id', how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate (and add) age at time of OP\n",
    "df_cohort['age_during_op'] = df_cohort['op_date_time'].dt.year - df_cohort['birth_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make NaN = -1\n",
    "df_cohort['age_during_op'] = df_cohort['age_during_op'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cases with missing values\n",
    "df_cohort = utils.exclude_rows(df_cohort, 'age_during_op', [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_cohort = df_cohort.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'pat_id': str,\n",
    "    # 'ops_code': str,\n",
    "    'female_sex': int,\n",
    "    'age_during_op': int\n",
    "})\n",
    "\n",
    "for column in ['admission_date_time', 'discharge_date_time', 'op_date_time', 'birth_date']:\n",
    "    df_cohort[f'{column}'] = pd.to_datetime(df_cohort[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables (Complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OP Times [WIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract by priority\n",
    "\n",
    "df_op_start_time = utils.extract_by_priority(\n",
    "    df=df_hierarchy, \n",
    "    column='value', \n",
    "    priority_order=['BEGAN', 'FREIG', 'ENDEL', 'SCHNI', 'EINSC']\n",
    "    )\n",
    "\n",
    "df_op_end_time = utils.extract_by_priority(\n",
    "    df=df_hierarchy, \n",
    "    column='value', \n",
    "    priority_order=['ENDAN', 'NAHT', 'BEGAW']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op_start_time = utils.handle_duplicates(\n",
    "    df=df_op_start_time, \n",
    "    column='case_id', \n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op_end_time = utils.handle_duplicates(\n",
    "    df=df_op_end_time, \n",
    "    column='case_id', \n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_op_start_time.rename(columns={'date_time': 'op_start_date_time'}, inplace=True)\n",
    "df_op_end_time.rename(columns={'date_time': 'op_end_date_time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort = pd.merge(df_cohort, df_op_start_time[['case_id', 'op_start_date_time']], on='case_id', how='left')\n",
    "df_cohort = pd.merge(df_cohort, df_op_end_time[['case_id', 'op_end_date_time']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort['op_start_date_time'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort['op_end_date_time'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: filter for OP dates (once more data is available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OP Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op_length = df_cohort[['case_id', 'op_start_date_time', 'op_end_date_time']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate length\n",
    "df_op_length['op_length'] = (df_op_length['op_end_date_time'] - df_op_length['op_start_date_time']).dt.total_seconds() / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_op_length = df_op_length.astype({\n",
    "    # 'case_id': str,\n",
    "    'op_length': float\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort = pd.merge(df_cohort, df_op_length[['case_id', 'op_length']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort['op_length'].notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASA Status [WIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract by priority\n",
    "df_asa_status = utils.extract_by_priority(\n",
    "    df=df_hierarchy, \n",
    "    column='variable', \n",
    "    priority_order=[\n",
    "        'BEH_ANAE_ASA_STATUS', 'Risiko_ASA', 'Behandlung_Anae_Praemed_ASA_Status', \n",
    "        'Praemedikation_ASA_Status'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asa_status = utils.handle_duplicates(\n",
    "    df=df_asa_status, \n",
    "    column='case_id', \n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_asa_status.rename(columns={'value': 'asa_status'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check variables\n",
    "df_hierarchy['variable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique value counts\n",
    "df_asa_status['asa_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all numbers\n",
    "\n",
    "def extract_number(value):\n",
    "    number = ''.join(filter(str.isdigit, str(value)))\n",
    "    return int(number) if number else np.nan\n",
    "\n",
    "df_asa_status['asa_status'] = df_asa_status['asa_status'].apply(extract_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check (new) unique value counts\n",
    "df_asa_status['asa_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asa_status_cleaned = df_asa_status.dropna(subset=['asa_status'])\n",
    "utils.get_amount_removed_rows(\n",
    "    initial=df_asa_status, \n",
    "    new=df_asa_status_cleaned\n",
    "    )\n",
    "df_asa_status = df_asa_status_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_asa_status = df_asa_status.astype({\n",
    "    # 'case_id': str,\n",
    "    'asa_status': int\n",
    "})\n",
    "\n",
    "for column in ['date_time']:\n",
    "    df_asa_status[f'{column}'] = pd.to_datetime(df_asa_status[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort = pd.merge(df_cohort, df_asa_status[['case_id', 'asa_status']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort['asa_status'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: filter for OP dates (once more data is available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight [WIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract by priority\n",
    "df_weight = utils.extract_by_priority(\n",
    "    df=df_hierarchy, \n",
    "    column='variable', \n",
    "    priority_order=[\n",
    "        'Patient_Gewicht', 'Praemedikation_Gewicht', 'Behandlung_Gewicht', 'Behandlung_Gewicht_Aufnahme', \n",
    "        'CO_klinStatus_Behandlung_Patient_Aufnahme_Gewicht_', 'CO_Patient_Aufnahme_Gewicht'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weight = utils.handle_duplicates(\n",
    "    df=df_weight, \n",
    "    column='case_id', \n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_weight.rename(columns={'value': 'weight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_weight = df_weight.astype({\n",
    "    # 'case_id': str,\n",
    "    'weight': float\n",
    "})\n",
    "\n",
    "for column in ['date_time']:\n",
    "    df_weight[f'{column}'] = pd.to_datetime(df_weight[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort = pd.merge(df_cohort, df_weight[['case_id', 'weight']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort['weight'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: filter for OP dates (once more data is available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height [WIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract by priority\n",
    "df_height = utils.extract_by_priority(\n",
    "    df=df_hierarchy, \n",
    "    column='variable', \n",
    "    priority_order=[\n",
    "        'Patient_Groesse', 'Praemedikation_Groesse', 'CO_klinStatus_Behandlung_Patient_Aufnahme_Groesse_', \n",
    "        'CO_Patient_Aufnahme_Groesse'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_height = utils.handle_duplicates(\n",
    "    df=df_height, \n",
    "    column='case_id', \n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_height.rename(columns={'value': 'height'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_height = df_height.astype({\n",
    "    # 'case_id': str,\n",
    "    'height': float\n",
    "})\n",
    "\n",
    "for column in ['date_time']:\n",
    "    df_height[f'{column}'] = pd.to_datetime(df_height[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort = pd.merge(df_cohort, df_height[['case_id', 'height']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort['height'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: filter for OP dates (once more data is available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmi = df_cohort[['case_id', 'weight', 'height']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmi['bmi'] = df_bmi['weight'] / ((df_bmi['height'] * 0.01) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_bmi = df_bmi.astype({\n",
    "    # 'case_id': str,\n",
    "    'bmi': float\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort = pd.merge(df_cohort, df_bmi[['case_id', 'bmi']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort['bmi'].notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elixhauser Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get elixhauser definitions\n",
    "df_elixhauser_definition = pd.read_csv('data/elixhauser.csv') # references: 10.1097/MLR.0b013e31819432e5; 10.1097/01.mlr.0000182534.19832.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map ICD-10 codes to Elixhauser categories (based on the implementation by Moritz Thiele)\n",
    "icd_to_category = {}\n",
    "for index, row in df_elixhauser_definition.iterrows():\n",
    "    for code in row['icd_codes'].split('|'):\n",
    "        icd_to_category[code] = row['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_icd_to_category(icd_code):\n",
    "    icd_code_str = str(icd_code) \n",
    "    for code in icd_to_category:\n",
    "        if icd_code_str.startswith(code): # add wildcard\n",
    "            return icd_to_category[code]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior_diagnoses_elixhauser = df_prior_diagnoses[['case_id', 'icd_code']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each diagnosis to its Elixhauser category\n",
    "df_prior_diagnoses_elixhauser['elixhauser_category'] = df_prior_diagnoses_elixhauser['icd_code'].apply(map_icd_to_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior_diagnoses_elixhauser.drop(columns=['icd_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table to create presence indicators for each category \n",
    "df_presence_absence = pd.pivot_table(df_prior_diagnoses_elixhauser, index='case_id', columns='elixhauser_category', \n",
    "                          aggfunc=lambda x: 1 if len(x) > 0 else 0, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "# df_presence_absence['case_id'] = df_presence_absence['case_id'].astype(str)\n",
    "category_columns = df_presence_absence.columns\n",
    "df_presence_absence[category_columns] = df_presence_absence[category_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presence_absence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_presence_absence_cleaned = df_presence_absence.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up column names\n",
    "df_presence_absence_cleaned.columns = df_presence_absence_cleaned.columns.str.lower().str.replace(' ', '_').str.replace(',', '') + '_elixhauser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add elixhauser categories to cohort\n",
    "df_cohort = pd.merge(df_cohort, df_presence_absence_cleaned, on='case_id', how='left', suffixes=('', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "elixhauser_columns = list(df_presence_absence_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort[elixhauser_columns] = df_cohort[elixhauser_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevated-Risk Surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with elevated risk surgery\n",
    "df_elevated_risk_surgery = utils.extract_df_data(\n",
    "    df=df_cohort, \n",
    "    filter_dict={\n",
    "        'ops_code':[\n",
    "            '^5-54', '^5-55', '^5-58', '^5-51', \n",
    "            '^5-32', '^5-35', '^5-42', '^5-38'\n",
    "            ]\n",
    "        }\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator to each case\n",
    "df_cohort['elevated_risk_surgery'] = df_cohort['case_id'].isin(df_elevated_risk_surgery['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ischemic Heart Disease History (MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with prior ischemic heart disease diagnosis\n",
    "df_MI_history = utils.extract_df_data(\n",
    "    df=df_prior_diagnoses, \n",
    "    filter_dict={\n",
    "        'icd_code':['^I21', '^I22', 'I25.2']\n",
    "        }\n",
    "    ) # reference: https://doi.org/10.1016/j.cjco.2022.07.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator to each case\n",
    "df_cohort['MI_history'] = df_cohort['case_id'].isin(df_MI_history['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cerebrovascular Disease History (CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with prior cerebrovascular disease diagnosis\n",
    "df_CD_history = utils.extract_df_data(\n",
    "    df=df_prior_diagnoses, \n",
    "    filter_dict={\n",
    "        'icd_code':[\n",
    "            '^G45', '^G46', 'H34.0', '^160', '^161', '^162', '^163', \n",
    "            '^164', '^165', '^166', '^167', '^168', '^169'\n",
    "            ]\n",
    "        }\n",
    "    ) # references: https://doi.org/10.1016/j.cjco.2022.07.008; https://doi.org/10.1038/s41591-024-03206-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator to each case\n",
    "df_cohort['CD_history'] = df_cohort['case_id'].isin(df_CD_history['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Insulin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with prior Insulin medication\n",
    "df_insulin = utils.extract_df_data(\n",
    "    df=df_prior_medication, \n",
    "    filter_dict={'medication': ['insulin']}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator to each case\n",
    "df_cohort['prior_insulin'] = df_cohort['case_id'].isin(df_insulin['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Creatinine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior_lab['substance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with prior creatinine (from blood)\n",
    "df_creatinine = utils.extract_df_data(\n",
    "    df=df_prior_lab, \n",
    "    filter_dict={\n",
    "        'substance':[\n",
    "            'Kreatinin (Jaff) HP', 'Kreatinin (Jaff)', \n",
    "            'Kreatinin (Jaff) (HP)', 'Kreatinin (enzym.) HP'\n",
    "            ]\n",
    "    },\n",
    "    exact_match=True\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check units\n",
    "df_creatinine['unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all other units\n",
    "df_creatinine = utils.exclude_rows(\n",
    "    df=df_creatinine, \n",
    "    column='unit', \n",
    "    items=['mg/dl'], \n",
    "    filter_operator=operator.eq\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert (use if other units are used that should be kept)\n",
    "conversion_factors = {\n",
    "    'mg/dl': 1,\n",
    "    'g/l': 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mg_dl(row):\n",
    "    quantity = row['quantity']\n",
    "    unit = row['unit']\n",
    "    factor = conversion_factors.get(unit, 1)\n",
    "    return quantity * factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert quantities\n",
    "df_creatinine['quantity_mg_dl'] = df_creatinine.apply(convert_to_mg_dl, axis=1)\n",
    "df_creatinine = df_creatinine.drop(columns=['unit', 'quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum all creatinine\n",
    "df_creatinine = utils.aggregate_data(\n",
    "    df=df_creatinine, \n",
    "    column='quantity_mg_dl', \n",
    "    method=utils.AggregationMethod.SUM, \n",
    "    rename=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sufficient quantity\n",
    "df_creatinine_cleaned = df_creatinine[df_creatinine['quantity_mg_dl_sum'] >= 2]\n",
    "utils.get_amount_removed_rows(\n",
    "    initial=df_creatinine, \n",
    "    new=df_creatinine_cleaned\n",
    "    )\n",
    "df_creatinine = df_creatinine_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_creatinine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator to each case\n",
    "df_cohort['prior_creatinine'] = df_cohort['case_id'].isin(df_creatinine['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vascular Disease History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD codes for vascular disease \n",
    "\n",
    "vascular_disorder = [\n",
    "    'I70.449',\n",
    "    'I70.638',\n",
    "    'I70.361',\n",
    "    'I70.599',\n",
    "    'I70.639',\n",
    "    'I70.692',\n",
    "    'I70.202',\n",
    "    'I70.601',\n",
    "    'E09.59',\n",
    "    'I70.703',\n",
    "    'I70.744',\n",
    "    'I70.732',\n",
    "    'I70.462',\n",
    "    'I70.663',\n",
    "    'I70.739',\n",
    "    'I70.718',\n",
    "    'I70.201',\n",
    "    'I70.513',\n",
    "    'E13.51',\n",
    "    'I70.338',\n",
    "    'I21.A9',\n",
    "    'I43',\n",
    "    'E10.65',\n",
    "    'I70.398',\n",
    "    'I70.369',\n",
    "    'I42.7',\n",
    "    'I70.411',\n",
    "    'I70.748',\n",
    "    'E10.59',\n",
    "    'I70.661',\n",
    "    'I70.221',\n",
    "    'I70.721',\n",
    "    'I73.1',\n",
    "    'I70.341',\n",
    "    'I70.743',\n",
    "    'I70.518',\n",
    "    'E11.51',\n",
    "    'I70.461',\n",
    "    'E10.51',\n",
    "    'I70.529',\n",
    "    'I70.745',\n",
    "    'I21.3',\n",
    "    'I70.245',\n",
    "    'I70.331',\n",
    "    'I70.218',\n",
    "    'I70.618',\n",
    "    'I22.9',\n",
    "    'I70.499',\n",
    "    'I70.301',\n",
    "    'I42.0',\n",
    "    'I70.432',\n",
    "    'I70.269',\n",
    "    'I22.0',\n",
    "    'I70.345',\n",
    "    'I70.441',\n",
    "    'I70.442',\n",
    "    'I70.428',\n",
    "    'I42.6',\n",
    "    'I70.528',\n",
    "    'I21.09',\n",
    "    'I70.568',\n",
    "    'I70.702',\n",
    "    'I70.708',\n",
    "    'I70.212',\n",
    "    'I70.791',\n",
    "    'I70.335',\n",
    "    'I21.02',\n",
    "    'I70.535',\n",
    "    'E08.59',\n",
    "    'I42.5',\n",
    "    'I70.348',\n",
    "    'I70.409',\n",
    "    'I70.738',\n",
    "    'I21.9',\n",
    "    'I70.291',\n",
    "    'I70.544',\n",
    "    'I21.01',\n",
    "    'I70.608',\n",
    "    'I70.769',\n",
    "    'I73.9',\n",
    "    'I70.213',\n",
    "    'I70.238',\n",
    "    'I70.332',\n",
    "    'I70.362',\n",
    "    'I70.445',\n",
    "    'I70.593',\n",
    "    'I70.649',\n",
    "    'I70.422',\n",
    "    'I70.719',\n",
    "    'I70.723',\n",
    "    'I70.733',\n",
    "    'I70.512',\n",
    "    'I70.313',\n",
    "    'I70.55',\n",
    "    'I70.693',\n",
    "    'I70.292',\n",
    "    'I70.648',\n",
    "    'I70.645',\n",
    "    'I70.519',\n",
    "    'I70.641',\n",
    "    'I70.368',\n",
    "    'I70.643',\n",
    "    'I70.399',\n",
    "    'I70.448',\n",
    "    'I70.35',\n",
    "    'I70.799',\n",
    "    'I70.344',\n",
    "    'I70.633',\n",
    "    'I70.642',\n",
    "    'I70.239',\n",
    "    'I70.25',\n",
    "    'I70.491',\n",
    "    'I70.592',\n",
    "    'I42.2',\n",
    "    'I70.268',\n",
    "    'I70.534',\n",
    "    'I70.731',\n",
    "    'E11.65',\n",
    "    'E13.52',\n",
    "    'I70.603',\n",
    "    'I70.219',\n",
    "    'I22.1',\n",
    "    'I70.363',\n",
    "    'I42.8',\n",
    "    'I70.349',\n",
    "    'I70.492',\n",
    "    'I70.562',\n",
    "    'I70.735',\n",
    "    'I70.91',\n",
    "    'I70.435',\n",
    "    'I70.208',\n",
    "    'I70.45',\n",
    "    'I70.634',\n",
    "    'I70.662',\n",
    "    'I70.793',\n",
    "    'I70.545',\n",
    "    'I70.669',\n",
    "    'I70.629',\n",
    "    'I70.561',\n",
    "    'I70.768',\n",
    "    'I70.298',\n",
    "    'I70.328',\n",
    "    'I70.429',\n",
    "    'I70.232',\n",
    "    'E11.59',\n",
    "    'I70.699',\n",
    "    'I70.8',\n",
    "    'I70.542',\n",
    "    'I70.498',\n",
    "    'I70.1',\n",
    "    'I70.309',\n",
    "    'I70.209',\n",
    "    'I70.244',\n",
    "    'I70.713',\n",
    "    'A18.84',\n",
    "    'I70.318',\n",
    "    'I70.401',\n",
    "    'I70.631',\n",
    "    'I70.749',\n",
    "    'I70.728',\n",
    "    'I70.668',\n",
    "    'I70.233',\n",
    "    'I70.623',\n",
    "    'I70.763',\n",
    "    'I70.333',\n",
    "    'I70.611',\n",
    "    'I70.722',\n",
    "    'I70.509',\n",
    "    'I70.533',\n",
    "    'I70.563',\n",
    "    'I70.229',\n",
    "    'I70.393',\n",
    "    'I70.299',\n",
    "    'E08.52',\n",
    "    'I42.1',\n",
    "    'I70.235',\n",
    "    'I70.241',\n",
    "    'I70.262',\n",
    "    'I70.311',\n",
    "    'I42.4',\n",
    "    'I70.391',\n",
    "    'I70.402',\n",
    "    'I70.522',\n",
    "    'I70.303',\n",
    "    'I70.691',\n",
    "    'I22.2',\n",
    "    'I70.334',\n",
    "    'I70.439',\n",
    "    'I70.742',\n",
    "    'I70.792',\n",
    "    'I70.263',\n",
    "    'E13.59',\n",
    "    'I70.632',\n",
    "    'I21.A1',\n",
    "    'I70.308',\n",
    "    'I70.469',\n",
    "    'E09.52',\n",
    "    'I70.223',\n",
    "    'I70.242',\n",
    "    'I70.408',\n",
    "    'I70.203',\n",
    "    'I70.493',\n",
    "    'I70.548',\n",
    "    'I70.75',\n",
    "    'I42.9',\n",
    "    'I70.501',\n",
    "    'I70.321',\n",
    "    'I70.443',\n",
    "    'I70.421',\n",
    "    'E10.52',\n",
    "    'I70.711',\n",
    "    'I70.549',\n",
    "    'I70.302',\n",
    "    'I70.423',\n",
    "    'I70.434',\n",
    "    'I70.231',\n",
    "    'I70.591',\n",
    "    'I70.628',\n",
    "    'I70.612',\n",
    "    'I70.644',\n",
    "    'I70.701',\n",
    "    'I70.438',\n",
    "    'I70.538',\n",
    "    'I70.234',\n",
    "    'I70.248',\n",
    "    'I70.433',\n",
    "    'I70.569',\n",
    "    'I70.709',\n",
    "    'I70.403',\n",
    "    'E11.52',\n",
    "    'I70.90',\n",
    "    'I70.621',\n",
    "    'I21.4',\n",
    "    'I70.243',\n",
    "    'I70.712',\n",
    "    'I70.602',\n",
    "    'I70.539',\n",
    "    'I70.329',\n",
    "    'I70.762',\n",
    "    'I70.322',\n",
    "    'E08.65',\n",
    "    'I70.312',\n",
    "    'I70.502',\n",
    "    'I70.503',\n",
    "    'I70.211',\n",
    "    'I70.622',\n",
    "    'I70.419',\n",
    "    'I70.228',\n",
    "    'I70.463',\n",
    "    'I70.511',\n",
    "    'I70.521',\n",
    "    'I70.65',\n",
    "    'I70.532',\n",
    "    'I79.8',\n",
    "    'I70.468',\n",
    "    'I70.543',\n",
    "    'I70.343',\n",
    "    'I70.392',\n",
    "    'I70.508',\n",
    "    'I70.418',\n",
    "    'I70.609',\n",
    "    'I70.698',\n",
    "    'I70.249',\n",
    "    'I70.531',\n",
    "    'I70.598',\n",
    "    'I70.339',\n",
    "    'I70.734',\n",
    "    'I70.413',\n",
    "    'I70.613',\n",
    "    'I79.1',\n",
    "    'I21.21',\n",
    "    'I22.8',\n",
    "    'I70.541',\n",
    "    'I70.222',\n",
    "    'I42.3',\n",
    "    'I21.11',\n",
    "    'I70.619',\n",
    "    'I70.412',\n",
    "    'I70.635',\n",
    "    'I70.92',\n",
    "    'E09.51',\n",
    "    'I21.29',\n",
    "    'I70.523',\n",
    "    'I70.342',\n",
    "    'I70.444',\n",
    "    'E08.51',\n",
    "    'I70.323',\n",
    "    'I70.729',\n",
    "    'I70.798',\n",
    "    'I70.0',\n",
    "    'I70.319',\n",
    "    'I21.19',\n",
    "    'I70.761',\n",
    "    'I70.261',\n",
    "    'I70.293',\n",
    "    'I70.741',\n",
    "    'I70.431'\n",
    "    ] # reference: https://doi.org/10.1002/pds.4973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with prior vascular disease diagnosis\n",
    "df_vascular_history = utils.extract_df_data(\n",
    "    df=df_prior_diagnoses, \n",
    "    filter_dict={'icd_code':vascular_disorder}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator to each case\n",
    "df_cohort['vascular_disease_history'] = df_cohort['case_id'].isin(df_vascular_history['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroke / TIA / Thromboembolism History (STT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "STT = [\n",
    "    'I63.423',\n",
    "    'I74.11',\n",
    "    'I63.239',\n",
    "    'I60.12',\n",
    "    'I74.2',\n",
    "    'I63.119',\n",
    "    'T80.0XXA',\n",
    "    'I63.449',\n",
    "    'I60.2',\n",
    "    'I63.032',\n",
    "    'I63.232',\n",
    "    'I61.1',\n",
    "    'I63.211',\n",
    "    'I63.22',\n",
    "    'I74.19',\n",
    "    'I60.9',\n",
    "    'I63.012',\n",
    "    'I63.539',\n",
    "    'I74.4',\n",
    "    'I63.30',\n",
    "    'I63.531',\n",
    "    'I63.549',\n",
    "    'I74.09',\n",
    "    'I63.00',\n",
    "    'I63.421',\n",
    "    'I63.519',\n",
    "    'I74.8',\n",
    "    'I63.412',\n",
    "    'I60.52',\n",
    "    'I63.321',\n",
    "    'I63.132',\n",
    "    'G46.0',\n",
    "    'I63.59',\n",
    "    'I63.419',\n",
    "    'I63.429',\n",
    "    'I63.441',\n",
    "    'I61.3',\n",
    "    'I63.543',\n",
    "    'G45.2',\n",
    "    'I63.432',\n",
    "    'I63.113',\n",
    "    'I63.09',\n",
    "    'G45.0',\n",
    "    'I63.131',\n",
    "    'T82.818A',\n",
    "    'I74.9',\n",
    "    'I61.2',\n",
    "    'I60.4',\n",
    "    'I63.339',\n",
    "    'I63.219',\n",
    "    'I63.031',\n",
    "    'I67.89',\n",
    "    'I60.10',\n",
    "    'I26.02',\n",
    "    'I63.20',\n",
    "    'I63.411',\n",
    "    'I61.0',\n",
    "    'I74.5',\n",
    "    'I63.139',\n",
    "    'I63.111',\n",
    "    'I63.331',\n",
    "    'I63.533',\n",
    "    'I63.323',\n",
    "    'I63.40',\n",
    "    'I63.532',\n",
    "    'I60.7',\n",
    "    'I63.422',\n",
    "    'I60.30',\n",
    "    'I60.00',\n",
    "    'I60.51',\n",
    "    'I61.9',\n",
    "    'T82.817A',\n",
    "    'I63.349',\n",
    "    'I63.311',\n",
    "    'I63.319',\n",
    "    'G45.8',\n",
    "    'I63.212',\n",
    "    'I63.513',\n",
    "    'I26.90',\n",
    "    'I74.3',\n",
    "    'I63.233',\n",
    "    'I63.343',\n",
    "    'I63.333',\n",
    "    'I63.512',\n",
    "    'I63.8',\n",
    "    'I74.10',\n",
    "    'I63.133',\n",
    "    'I60.50',\n",
    "    'I63.341',\n",
    "    'I63.542',\n",
    "    'G45.1',\n",
    "    'I61.6',\n",
    "    'I60.8',\n",
    "    'G45.9',\n",
    "    'I63.439',\n",
    "    'I63.541',\n",
    "    'I63.39',\n",
    "    'I63.50',\n",
    "    'I63.413',\n",
    "    'I63.6',\n",
    "    'I63.431',\n",
    "    'I67.848',\n",
    "    'I63.013',\n",
    "    'I63.19',\n",
    "    'I26.01',\n",
    "    'I61.4',\n",
    "    'I60.6',\n",
    "    'T81.718A',\n",
    "    'I63.313',\n",
    "    'I63.529',\n",
    "    'I63.29',\n",
    "    'I63.231',\n",
    "    'I26.09',\n",
    "    'I60.11',\n",
    "    'I61.8',\n",
    "    'I60.32',\n",
    "    'I63.12',\n",
    "    'I63.521',\n",
    "    'I63.442',\n",
    "    'I60.02',\n",
    "    'I63.342',\n",
    "    'I60.31',\n",
    "    'I26.92',\n",
    "    'I63.523',\n",
    "    'I63.329',\n",
    "    'I63.033',\n",
    "    'I60.01',\n",
    "    'I67.841',\n",
    "    'I74.01',\n",
    "    'I61.5',\n",
    "    'I63.443',\n",
    "    'I63.332',\n",
    "    'I63.10',\n",
    "    'G46.2',\n",
    "    'I63.322',\n",
    "    'G46.1',\n",
    "    'I63.02',\n",
    "    'I63.312',\n",
    "    'I63.511',\n",
    "    'I63.011',\n",
    "    'I63.522',\n",
    "    'I63.433',\n",
    "    'I26.99',\n",
    "    'I63.019',\n",
    "    'I63.49',\n",
    "    'I63.9',\n",
    "    'T81.72XA',\n",
    "    'I63.213',\n",
    "    'I63.112',\n",
    "    'I63.039'\n",
    " ] # reference: https://doi.org/10.1002/pds.4973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with prior STT diagnosis\n",
    "df_STT_history = utils.extract_df_data(\n",
    "    df=df_prior_diagnoses, \n",
    "    filter_dict={'icd_code':STT}\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator to each case\n",
    "df_cohort['STT_history'] = df_cohort['case_id'].isin(df_STT_history['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atrial Fibrillation (AF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with prior atrial fibrillation and flutter diagnosis\n",
    "df_AF_history = utils.extract_df_data(\n",
    "    df=df_prior_diagnoses, \n",
    "    filter_dict={'icd_code':['^I48']}\n",
    "    ) # reference: https://doi.org/10.1038/s41591-024-03206-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator to each case\n",
    "df_cohort['AF_history'] = df_cohort['case_id'].isin(df_AF_history['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanded RCRI Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_RCRI_weights = pd.read_csv('data/expanded-RCRI-logit-weights.csv')\n",
    "df_expanded_RCRI_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean features\n",
    "filtered_values = df_expanded_RCRI_weights['feature'][df_expanded_RCRI_weights['feature'].str.endswith('_ICD_history')]\n",
    "cleaned_values = filtered_values.str.replace('_ICD_history', '', regex=False)\n",
    "expanded_RCRI_features = cleaned_values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in expanded_RCRI_features:    \n",
    "    icd_pattern = f'^{feature}'\n",
    "    df_feature = utils.extract_df_data(\n",
    "        df=df_prior_diagnoses, \n",
    "        filter_dict={'icd_code':[icd_pattern]}\n",
    "        )\n",
    "    df_cohort[f'{feature}_ICD_history'] = df_cohort['case_id'].isin(df_feature['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanded CHA2DS2-VASc Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_CHA_weights = pd.read_csv('data/expanded-CHA-logit-weights.csv')\n",
    "df_expanded_CHA_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean features\n",
    "filtered_values = df_expanded_CHA_weights['feature'][df_expanded_CHA_weights['feature'].str.endswith('_ICD_history')]\n",
    "cleaned_values = filtered_values.str.replace('_ICD_history', '', regex=False)\n",
    "expanded_CHA_features = cleaned_values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in expanded_CHA_features:    \n",
    "    icd_pattern = f'^{feature}'\n",
    "    df_feature = utils.extract_df_data(\n",
    "        df=df_prior_diagnoses, \n",
    "        filter_dict={'icd_code':[icd_pattern]}\n",
    "        )\n",
    "    df_cohort[f'{feature}_ICD_history'] = df_cohort['case_id'].isin(df_feature['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanded Elixhauser Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_elix_weights = pd.read_csv('data/expanded-elixhauser-logit-weights.csv')\n",
    "df_expanded_elix_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean features\n",
    "filtered_values = df_expanded_elix_weights['feature'][df_expanded_elix_weights['feature'].str.endswith('_ICD_history')]\n",
    "cleaned_values = filtered_values.str.replace('_ICD_history', '', regex=False)\n",
    "expanded_elix_features = cleaned_values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in expanded_elix_features:    \n",
    "    icd_pattern = f'^{feature}'\n",
    "    df_feature = utils.extract_df_data(\n",
    "        df=df_prior_diagnoses, \n",
    "        filter_dict={'icd_code':[icd_pattern]}\n",
    "        )\n",
    "    df_cohort[f'{feature}_ICD_history'] = df_cohort['case_id'].isin(df_feature['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variables for cases that died\n",
    "df_mortality = utils.extract_df_data(df_npat, filter_dict={'died': [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only those during hospital stay of OP cases\n",
    "df_mortality = utils.filter_time_between(\n",
    "    df=df_mortality, \n",
    "    time_column='death_date_time', \n",
    "    df_time_reference=df_cohort, \n",
    "    between=True, \n",
    "    df_time_reference_column_upper_bound='discharge_date_time', \n",
    "    df_time_reference_column_lower_bound='admission_date_time', \n",
    "    merge_on='case_id'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator to cohort\n",
    "df_cohort['in_hospital_death'] = df_cohort['case_id'].isin(df_mortality['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_forward_backward = [\n",
    "    'I74.11',\n",
    "    'I26.09',\n",
    "    'I74.2',\n",
    "    'I26.90',\n",
    "    'I74.3',\n",
    "    'T80.0XXA',\n",
    "    'T82.818A',\n",
    "    'I74.9',\n",
    "    'I26.92',\n",
    "    'I74.19',\n",
    "    'I74.10',\n",
    "    'I26.02',\n",
    "    'I74.4',\n",
    "    'I74.01',\n",
    "    'I74.5',\n",
    "    'I74.09',\n",
    "    'I74.8',\n",
    "    'I26.99',\n",
    "    'I26.01',\n",
    "    'T82.817A',\n",
    "    'T81.72XA',\n",
    "    'T81.718A'\n",
    "    ] # reference: https://doi.org/10.1002/pds.4973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_nature = ['^I63.', 'I67.81', 'I67.89', 'I67.9', 'G45.1', 'G45.8', 'I67.89'] # reference: https://doi.org/10.1038/s41591-024-03206-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes for stroke \n",
    "OPS_stroke = ['^8-836.80'] \n",
    "ICD_stroke = stroke_forward_backward + stroke_nature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with stroke diagnosis 30 days after OP\n",
    "df_ICD_stroke = utils.extract_df_data(\n",
    "    df=df_diagnoses_30_days, \n",
    "    filter_dict={'icd_code':ICD_stroke}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ICD_stroke = df_ICD_stroke[['case_id', 'icd_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_ICD_stroke = df_ICD_stroke.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'icd_code': str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ICD_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ICD_stroke['icd_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prodecures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with stroke procedure\n",
    "df_OPS_stroke = utils.extract_df_data(\n",
    "    df=df_procedures_30_days, \n",
    "    filter_dict={'ops_code': OPS_stroke}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPS_stroke  = df_OPS_stroke[['case_id', 'ops_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_OPS_stroke = df_OPS_stroke.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'ops_code': str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPS_stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPS_stroke['ops_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICD_OPS_stroke = set(df_ICD_stroke['case_id']).union(set(df_OPS_stroke['case_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to cohort\n",
    "df_cohort['stroke_30_days'] = df_cohort['case_id'].isin(ICD_OPS_stroke).astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes for MACE \n",
    "\n",
    "OPS_MACE = ['^5-36', '^8-84'] \n",
    "\n",
    "acute_myocardial_infarction = ['^I21' '^I22'] # reference: https://doi.org/10.1016/j.cjco.2022.07.008\n",
    "non_fatal_cardiac_arrest_or_ventricular_arrythmia = ['I47.2', 'I49.01', 'I49.02', 'I46.9', 'I49.9', '^R99'] # reference: https://doi.org/10.1016/j.cjco.2022.07.008\n",
    "ICD_MACE = acute_myocardial_infarction + non_fatal_cardiac_arrest_or_ventricular_arrythmia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with MACE diagnosis 30 days after OP\n",
    "df_ICD_MACE = utils.extract_df_data(\n",
    "    df=df_diagnoses_30_days, \n",
    "    filter_dict={'icd_code':ICD_MACE}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ICD_MACE  = df_ICD_MACE[['case_id', 'icd_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_ICD_MACE = df_ICD_MACE.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'icd_code': str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ICD_MACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ICD_MACE['icd_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prodecures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cases with MACE procedure 30 days after OP\n",
    "df_OPS_MACE = utils.extract_df_data(\n",
    "    df=df_procedures_30_days, \n",
    "    filter_dict={'ops_code':OPS_MACE}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPS_MACE  = df_OPS_MACE[['case_id', 'ops_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_OPS_MACE = df_OPS_MACE.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'ops_code': str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPS_MACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OPS_MACE['ops_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICD_OPS_MACE = set(df_ICD_MACE['case_id']).union(set(df_OPS_MACE['case_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICD_OPS_MACE_DEATH =  set(ICD_OPS_MACE).union(set(df_mortality['case_id'])) # reference: https://doi.org/10.1016/j.cjco.2022.07.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort['MACE_30_days'] = df_cohort['case_id'].isin(ICD_OPS_MACE_DEATH).astype(int) # add to cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elixhauser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the implementation by Moritz Thiele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights\n",
    "# ahrq_weights = df_elixhauser_definition.set_index('category')['AHRQ_elixhauser_weights'].to_dict()\n",
    "van_walraven_weights = df_elixhauser_definition.set_index('category')['van_walraven_elixhauser_weights'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make score mutually exclusive for variants of hypertension and diabetes\n",
    "df_presence_absence.loc[df_presence_absence['Diabetes, complicated'] == 1, 'Diabetes, uncomplicated'] = 0\n",
    "df_presence_absence.loc[df_presence_absence['Hypertension, complicated'] == 1, 'Hypertension, uncomplicated'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scores\n",
    "van_walraven_scores = df_presence_absence.mul(van_walraven_weights, axis=1).sum(axis=1)\n",
    "# ahrq_scores = df_presence_absence.mul(ahrq_weights, axis=1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine scores\n",
    "df_elixhauser = pd.DataFrame({\n",
    "    'case_id': df_presence_absence.index,\n",
    "    # 'elixhauser_AHRQ': ahrq_scores.values,\n",
    "    'elixhauser_van_walraven': van_walraven_scores.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing\n",
    "df_elixhauser = df_elixhauser.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_elixhauser = df_elixhauser.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'icd_code': str\n",
    "    # 'elixhauser_AHRQ': int,\n",
    "    'elixhauser_van_walraven': int\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to cohort\n",
    "df_cohort = pd.merge(df_cohort, df_elixhauser, on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missings (of cohort)\n",
    "elixhauser_columns = ['elixhauser_van_walraven']\n",
    "df_cohort[elixhauser_columns] = df_cohort[elixhauser_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elixhauser = df_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elixhauser_weights = pd.read_csv('data/elixhauser-logit-weights.csv')\n",
    "df_elixhauser_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "elixhauser_features = [\n",
    "    'valvular_disease_elixhauser', 'blood_loss_anemia_elixhauser', 'alcohol_abuse_elixhauser', \n",
    "    'peptic_ulcer_disease_excluding_bleeding_elixhauser', 'psychoses_elixhauser', 'hypertension_uncomplicated_elixhauser', \n",
    "    'cardiac_arrhythmias_elixhauser', 'other_neurological_disorders_elixhauser', 'depression_elixhauser', \n",
    "    'hypertension_complicated_elixhauser', 'solid_tumor_without_metastasis_elixhauser', 'drug_abuse_elixhauser', \n",
    "    'diabetes_complicated_elixhauser', 'lymphoma_elixhauser', 'rheumatoid_arthritis/collagen_vascular_diseases_elixhauser', \n",
    "    'deficiency_anemia_elixhauser', 'metastatic_cancer_elixhauser', 'obesity_elixhauser', 'liver_disease_elixhauser', \n",
    "    'hypothyroidism_elixhauser', 'diabetes_uncomplicated_elixhauser', 'paralysis_elixhauser', 'aids/hiv_elixhauser', \n",
    "    'chronic_pulmonary_disease_elixhauser', 'pulmonary_circulation_disorders_elixhauser', 'peripheral_vascular_disorders_elixhauser', \n",
    "    'weight_loss_elixhauser', 'renal_failure_elixhauser', 'congestive_heart_failure_elixhauser', 'fluid_and_electrolyte_disorders_elixhauser', \n",
    "    'coagulopathy_elixhauser'\n",
    "    ]\n",
    "\n",
    "new_elixhauser_weights = analysis_utils.load_weights(\n",
    "    df=df_elixhauser_weights, \n",
    "    feature_column=elixhauser_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elixhauser['elixhauser_recalibrated'] = sum(\n",
    "    df_elixhauser[feature] * new_elixhauser_weights[feature] for feature in elixhauser_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elixhauser = df_elixhauser[['case_id', 'elixhauser_recalibrated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_elixhauser = df_elixhauser.astype({\n",
    "    # 'case_id': str,\n",
    "    'elixhauser_recalibrated': float,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elixhauser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to cohort\n",
    "df_cohort = pd.merge(df_cohort, df_elixhauser, on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanded Elixhauser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_elix = df_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_elix_weights = pd.read_csv('data/expanded-elixhauser-logit-weights.csv')\n",
    "df_expanded_elix_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_elix_features = list(df_expanded_elix_weights[df_expanded_elix_weights['feature'] != 'const']['feature'])\n",
    "\n",
    "expanded_elix_weights = analysis_utils.load_weights(\n",
    "    df=df_expanded_elix_weights, \n",
    "    feature_column=expanded_elix_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_elix['expanded_elixhauser'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_elix['expanded_elixhauser'] = sum(\n",
    "    df_expanded_elix[feature] * df_expanded_elix[feature] for feature in expanded_elix_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_elix = df_expanded_elix[['case_id', 'expanded_elixhauser']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_expanded_elix = df_expanded_elix.astype({\n",
    "    # 'case_id': str,\n",
    "    'expanded_elixhauser': float,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_elix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = pd.merge(df_cohort, df_expanded_elix, on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardiac Risk (RCRI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> based on [MDCalc](https://www.mdcalc.com/calc/1739/revised-cardiac-risk-index-pre-operative-risk)\n",
    "\n",
    "- high-risk surgery  -> intraperitoneal, intrathoracic, suprainguinal vascula, as obove (based on OPS of op) (```sap_nicp.csv```)\n",
    "- history of MI -> I21*, I22*, I23* (based on ICD-dx before OP) (```sap_ndia.csv```)\n",
    "- heart failure -> CHF (congestive heart failure) from Elixhauser [as in ```elix.ipynb```]\n",
    "- history of cerebrovascular disease  -> I63*, I65*, I66*, I67*, I68*, I69* (based on ICD-dx) (```sap_ndia.csv```)\n",
    "- preoperative insulin -> insulin in medications of co6 (```co6_medication.csv```)\n",
    "- preoperative creatinine >2 (last lab preop) -> from labs sap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RCRI = df_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "df_RCRI['RCRI_original'] = df_RCRI['elevated_risk_surgery'] * 1 \\\n",
    "    + df_RCRI['MI_history'] * 1 \\\n",
    "    + df_RCRI['congestive_heart_failure_elixhauser'] * 1 \\\n",
    "    + df_RCRI['CD_history'] * 1 \\\n",
    "    + df_RCRI['prior_insulin'] * 1 \\\n",
    "    + df_RCRI['prior_creatinine'] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RCRI_weights = pd.read_csv('data/RCRI-logit-weights.csv')\n",
    "df_RCRI_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCRI_features = [\n",
    "    'elevated_risk_surgery', 'MI_history', 'congestive_heart_failure_elixhauser', \n",
    "    'CD_history', 'prior_insulin', 'prior_creatinine'\n",
    "    ]\n",
    "\n",
    "new_RCRI_weights = analysis_utils.load_weights(\n",
    "    df=df_RCRI_weights, \n",
    "    feature_column=RCRI_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalibrated\n",
    "df_RCRI['RCRI_recalibrated'] = df_RCRI['elevated_risk_surgery'] * new_RCRI_weights['elevated_risk_surgery'] \\\n",
    "    + df_RCRI['MI_history'] * new_RCRI_weights['MI_history'] \\\n",
    "    + df_RCRI['congestive_heart_failure_elixhauser'] * new_RCRI_weights['congestive_heart_failure_elixhauser'] \\\n",
    "    + df_RCRI['CD_history'] * new_RCRI_weights['CD_history']  \\\n",
    "    + df_RCRI['prior_insulin'] * new_RCRI_weights['prior_insulin']  \\\n",
    "    + df_RCRI['prior_creatinine'] * new_RCRI_weights['prior_creatinine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RCRI = df_RCRI[['case_id', 'RCRI_recalibrated', 'RCRI_original']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_RCRI = df_RCRI.astype({\n",
    "    # 'case_id': str,\n",
    "    'RCRI_recalibrated': float,\n",
    "    'RCRI_original': float\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RCRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to cohort\n",
    "df_cohort = pd.merge(df_cohort, df_RCRI, on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardiac Risk (Expanded RCRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_RCRI = df_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_RCRI_weights = pd.read_csv('data/expanded-RCRI-logit-weights.csv')\n",
    "df_expanded_RCRI_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_RCRI_features = list(df_expanded_RCRI_weights[df_expanded_RCRI_weights['feature'] != 'const']['feature'])\n",
    "\n",
    "expanded_RCRI_weights = analysis_utils.load_weights(\n",
    "    df=df_expanded_RCRI_weights, \n",
    "    feature_column=expanded_RCRI_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_RCRI['expanded_RCRI'] = sum(\n",
    "    df_expanded_RCRI[feature] * expanded_RCRI_weights[feature] for feature in expanded_RCRI_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_RCRI = df_expanded_RCRI[['case_id', 'expanded_RCRI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_expanded_RCRI = df_expanded_RCRI.astype({\n",
    "    # 'case_id': str,\n",
    "    'expanded_RCRI': float,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_RCRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to cohort\n",
    "df_cohort = pd.merge(df_cohort, df_expanded_RCRI, on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroke Risk (CHA2DS2-VASc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> based on [MDCalc](https://www.mdcalc.com/calc/801/cha2ds2-vasc-score-atrial-fibrillation-stroke-risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CHA = df_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get risk (points) for each age category\n",
    "def age_risk(age):\n",
    "    if age < 65:\n",
    "        return 0\n",
    "    elif age >= 65 and age < 75:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "df_CHA['CHA2DS2_VASc_original'] = df_CHA['female_sex'] * 1 \\\n",
    "    + df_CHA['congestive_heart_failure_elixhauser'] * 1 \\\n",
    "    + (df_CHA['hypertension_uncomplicated_elixhauser'] + df_CHA['hypertension_complicated_elixhauser']) * 1 \\\n",
    "    + (df_CHA['diabetes_uncomplicated_elixhauser'] + df_CHA['diabetes_complicated_elixhauser']) * 1 \\\n",
    "    + df_CHA['vascular_disease_history'] * 1 \\\n",
    "    + df_CHA['STT_history'] * 2 \\\n",
    "    + df_CHA['age_during_op'].apply(age_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CHA_weights = pd.read_csv('data/CHA-logit-weights.csv')\n",
    "df_CHA_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHA_features = {\n",
    "    'female_sex', 'congestive_heart_failure_elixhauser', 'hypertension_uncomplicated_elixhauser', \n",
    "    'hypertension_complicated_elixhauser', 'diabetes_uncomplicated_elixhauser', 'diabetes_complicated_elixhauser', \n",
    "    'vascular_disease_history', 'STT_history', 'age_below_65', 'age_between_65_and_74', 'age_above_74'\n",
    "    }\n",
    "\n",
    "new_CHA_weights = analysis_utils.load_weights(\n",
    "    df=df_CHA_weights, \n",
    "    feature_column=CHA_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_risk_recalibrated(age):\n",
    "    if age < 65:\n",
    "        return new_CHA_weights['age_below_65']\n",
    "    elif age >= 65 and age < 75:\n",
    "        return new_CHA_weights['age_between_65_and_74']\n",
    "    else:\n",
    "        return new_CHA_weights['age_above_74']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalibrated\n",
    "df_CHA['CHA2DS2_VASc_recalibrated'] = df_CHA['female_sex'] * new_CHA_weights['female_sex'] \\\n",
    "    + df_CHA['congestive_heart_failure_elixhauser'] * new_CHA_weights['congestive_heart_failure_elixhauser'] \\\n",
    "    + df_CHA['hypertension_uncomplicated_elixhauser'] * new_CHA_weights['hypertension_uncomplicated_elixhauser'] \\\n",
    "    + df_CHA['hypertension_complicated_elixhauser'] * new_CHA_weights['hypertension_complicated_elixhauser'] \\\n",
    "    + df_CHA['diabetes_uncomplicated_elixhauser'] * new_CHA_weights['diabetes_complicated_elixhauser'] \\\n",
    "    + df_CHA['diabetes_complicated_elixhauser'] * new_CHA_weights['diabetes_uncomplicated_elixhauser'] \\\n",
    "    + df_CHA['vascular_disease_history'] * new_CHA_weights['vascular_disease_history'] \\\n",
    "    + df_CHA['STT_history'] * new_CHA_weights['STT_history'] \\\n",
    "    + df_CHA['age_during_op'].apply(age_risk_recalibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CHA = df_CHA[['case_id', 'CHA2DS2_VASc_recalibrated', 'CHA2DS2_VASc_original']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_CHA = df_CHA.astype({\n",
    "    # 'case_id': str,\n",
    "    'CHA2DS2_VASc_recalibrated': float,\n",
    "    'CHA2DS2_VASc_original': float\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to cohort\n",
    "df_cohort = pd.merge(df_cohort, df_CHA, on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stroke Risk (Expanded CHA2DS2-VASc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_CHA = df_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_CHA_weights = pd.read_csv('data/expanded-CHA-logit-weights.csv')\n",
    "df_expanded_CHA_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_CHA_features = list(df_expanded_CHA_weights[df_expanded_CHA_weights['feature'] != 'const']['feature'])\n",
    "\n",
    "expanded_CHA_weights = analysis_utils.load_weights(\n",
    "    df=df_expanded_CHA_weights, \n",
    "    feature_column=expanded_CHA_features\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_risk_expanded(age):\n",
    "    if age < 65:\n",
    "        return expanded_CHA_weights['age_below_65']\n",
    "    elif age >= 65 and age < 75:\n",
    "        return expanded_CHA_weights['age_between_65_and_74']\n",
    "    else:\n",
    "        return expanded_CHA_weights['age_above_74']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_CHA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_CHA_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_CHA['expanded_CHA2DS2_VASc'] = 0\n",
    "\n",
    "for feature in expanded_CHA_features:\n",
    "    if feature != 'age_below_65' and feature != 'age_between_65_and_74' and feature != 'age_above_74':\n",
    "        df_expanded_CHA['expanded_CHA2DS2_VASc'] += df_expanded_CHA[feature] * expanded_CHA_weights[feature]\n",
    "\n",
    "df_expanded_CHA['expanded_CHA2DS2_VASc'] += df_expanded_CHA['age_during_op'].apply(age_risk_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_CHA = df_expanded_CHA[['case_id', 'expanded_CHA2DS2_VASc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "df_expanded_CHA = df_expanded_CHA.astype({\n",
    "    # 'case_id': str,\n",
    "    'expanded_CHA2DS2_VASc': float,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_CHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to cohort\n",
    "df_cohort = pd.merge(df_cohort, df_expanded_CHA, on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulmonary Risk (ARISCAT) [WIP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinically Implausible Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = utils.clean_values(\n",
    "    df=df_cohort, \n",
    "    reference_values='data/reference-values.csv', \n",
    "    drop_rows=False # only set to missing\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all cardiac surgeries\n",
    "df_cohort_cleaned = df_cohort[~df_cohort['ops_code'].str.startswith(('5-35', '5-36', '5-37'))] # reference: https://klassifikationen.bfarm.de/ops/kode-suche/htmlops2023/block-5-35...5-37.htm\n",
    "utils.get_amount_removed_rows(\n",
    "    initial=df_cohort, \n",
    "    new=df_cohort_cleaned\n",
    "    )\n",
    "df_cohort = df_cohort_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = utils.clean_values(\n",
    "    df=df_cohort, \n",
    "    reference_values='data/reference-values-exclusion.csv', \n",
    "    drop_rows=True\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2005-01-01' # as there is a big jump from 2004 to 2005\n",
    "end_date = '2024-09-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = utils.exclude_rows(\n",
    "    df=df_cohort, \n",
    "    column='admission_date_time', \n",
    "    items=[start_date], \n",
    "    filter_operator=operator.le\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = utils.exclude_rows(\n",
    "    df=df_cohort, \n",
    "    column='discharge_date_time', \n",
    "    items=[start_date], \n",
    "    filter_operator=operator.le\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = utils.exclude_rows(\n",
    "    df=df_cohort, \n",
    "    column='op_date_time', \n",
    "    items=[start_date], \n",
    "    filter_operator=operator.le\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = utils.exclude_rows(\n",
    "    df=df_cohort, \n",
    "    column='admission_date_time', \n",
    "    items=[end_date], \n",
    "    filter_operator=operator.ge\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = utils.exclude_rows(\n",
    "    df=df_cohort, \n",
    "    column='discharge_date_time', \n",
    "    items=[end_date], \n",
    "    filter_operator=operator.ge\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = utils.exclude_rows(\n",
    "    df=df_cohort, \n",
    "    column='op_date_time', \n",
    "    items=[end_date], \n",
    "    filter_operator=operator.ge\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (lambda row: row['female_sex'] == 1, 'female'),\n",
    "    (lambda row: row['female_sex'] == 0, 'male'),\n",
    "    (lambda row: row['campus'] == 'M', 'campus_mitte'),\n",
    "    (lambda row: row['campus'] == 'S', 'campus_steglitz'),\n",
    "    (lambda row: row['campus'] == 'W', 'campus_wedding'),\n",
    "    (lambda row: row['age_during_op'] > 65, 'age_above_65'),\n",
    "    (lambda row: row['age_during_op'] < 65, 'age_below_65'),\n",
    "    (lambda row: (row['age_during_op'] >= 65) and (row['age_during_op'] < 74), 'age_between_65_and_74'),\n",
    "    (lambda row: row['age_during_op'] > 74, 'age_above_74'),\n",
    "    (lambda row: row['asa_status'] <= 2, 'asa_le_2'),\n",
    "    (lambda row: row['asa_status'] > 2, 'asa_gt_2'),\n",
    "    (lambda row: row['admission_date_time'].day == row['op_date_time'].day == row['discharge_date_time'].day, 'ambulatory'),\n",
    "    (lambda row: row['admission_date_time'].day < row['op_date_time'].day < row['discharge_date_time'].day, 'inpatient'),\n",
    "    (lambda row: row['admission_date_time'].day == row['op_date_time'].day < row['discharge_date_time'].day, 'SDA')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = utils.create_subgroups(\n",
    "    df=df_cohort, \n",
    "    conditions=conditions\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report (Full Cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_report = ProfileReport(df=df_cohort, title='Cohort', minimal=True)\n",
    "cohort_report.to_file('data/cohort_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (All Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ```df_op``` all cases with OP\n",
    "- ```df_op_cohort``` all cohort cases with OP\n",
    "- ```df_cohort``` only earliest OP of cohort (main table for analysis)\n",
    "- ```df_ndia``` all diagnoses\n",
    "- ```df_prior_diagnoses``` all diagnoses prior to OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_eda = df_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op_eda = df_op.copy()\n",
    "df_op_cohort_eda = df_op_cohort.copy()\n",
    "df_diagnoses_eda = df_ndia.copy()\n",
    "df_prior_diagnoses_eda = df_prior_diagnoses.copy()\n",
    "df_elixhauser_definition_eda = df_elixhauser_definition.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op_eda.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_op_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op_eda['ops_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_op_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op_cohort_eda.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_op_cohort_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op_cohort_eda['ops_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_eda.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_cohort_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admission Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_counts = df_cohort['admission_date_time'].dt.year.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(yearly_counts.index, yearly_counts.values)\n",
    "plt.xlabel('Year of Admission')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Cases per Year')\n",
    "plt.xticks(yearly_counts.index) \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OP Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_counts = df_cohort['op_date_time'].dt.year.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(yearly_counts.index, yearly_counts.values)\n",
    "plt.xlabel('Year of OP')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Cases per Year')\n",
    "plt.xticks(yearly_counts.index) \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OP Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df_cohort['ops_code'].value_counts()\n",
    "df_value_counts = value_counts.reset_index()\n",
    "df_value_counts.columns = ['ops_code', 'count']\n",
    "df_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_counts.to_csv('data/ops_codes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_dates = pd.to_datetime(df_cohort_eda['admission_date_time'])\n",
    "discharge_dates = pd.to_datetime(df_cohort_eda['discharge_date_time'])\n",
    "length_of_stay = discharge_dates - admission_dates\n",
    "length_of_stay = length_of_stay.fillna(pd.NaT)\n",
    "\n",
    "df_length_of_stay = pd.DataFrame({\n",
    "    'case_id': df_cohort_eda['case_id'],\n",
    "    'length_of_stay': length_of_stay\n",
    "})\n",
    "\n",
    "utils.get_eda_metrics(df_length_of_stay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_discharge = df_cohort_eda[df_cohort_eda['discharge_date_time'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_discharge['admission_end_of_2024'] = missing_discharge['admission_date_time'].dt.year >= 2024\n",
    "missing_discharge['admission_end_of_2024'] &= missing_discharge['admission_date_time'].dt.month >= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_discharge = missing_discharge[['case_id', 'in_hospital_death', 'admission_end_of_2024']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of unique cases with missing discharge date: {missing_discharge[\"case_id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of duplicate cases with missing discharge date: {missing_discharge.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_discharge_death = missing_discharge[missing_discharge['in_hospital_death'] == 1]\n",
    "\n",
    "print(f'Number of unique in hospital death cases with missing discharge date: {missing_discharge_death[\"case_id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_discharge_end = missing_discharge[missing_discharge['admission_end_of_2024']]\n",
    "\n",
    "print(f'Number of unique late 2024 admission cases with missing discharge date: {missing_discharge_end[\"case_id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elixhauser Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elixhauser_categories = df_elixhauser_definition_eda['category'].tolist()\n",
    "elixhauser_categories = [category + '_elixhauser' for category in elixhauser_categories]\n",
    "elixhauser_categories = [category.lower().replace(' ', '_') for category in elixhauser_categories]\n",
    "elixhauser_categories = [category.replace(',', '') for category in elixhauser_categories]\n",
    "elixhauser_diagnoses_count = df_cohort_eda[df_cohort_eda[elixhauser_categories].any(axis=1)]['case_id'].nunique()\n",
    "patient_count = df_cohort_eda['pat_id'].nunique()\n",
    "\n",
    "print(f'Number of patients with (prior) Elixhauser diagnosis: {elixhauser_diagnoses_count} ({round((elixhauser_diagnoses_count / patient_count) * 100, 2) }%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_count = df_cohort_eda['stroke_30_days'].sum() \n",
    "patient_count = df_cohort_eda['pat_id'].nunique()\n",
    "\n",
    "print(f'Number of patients with stroke 30 days after OP: {stroke_count} ({round((stroke_count / patient_count) * 100, 2) }%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACE_count = df_cohort_eda['MACE_30_days'].sum() \n",
    "patient_count = df_cohort_eda['pat_id'].nunique()\n",
    "\n",
    "print(f'Number of patients with MACE 30 days after OP: {MACE_count} ({round((MACE_count / patient_count) * 100, 2) }%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_count = df_cohort_eda['in_hospital_death'].sum() \n",
    "patient_count = df_cohort_eda['pat_id'].nunique()\n",
    "\n",
    "print(f'Number of patients who died during hospital stay: {death_count} ({round((death_count / patient_count) * 100, 2) }%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Risk Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_risk_cohort = df_cohort_eda.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elixhauser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lowest value of top risk category\n",
    "quantile = 0.85\n",
    "elixhauser_threshold = df_high_risk_cohort['elixhauser_van_walraven'].quantile(quantile)\n",
    "df_top_elixhauser_cases = df_high_risk_cohort[df_high_risk_cohort['elixhauser_van_walraven'] >= elixhauser_threshold]\n",
    "min_elixhauser_threshold = df_top_elixhauser_cases['elixhauser_van_walraven'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get percentage of deaths in this category\n",
    "death_count_total = df_high_risk_cohort['in_hospital_death'].sum()\n",
    "death_count_top_cases = df_top_elixhauser_cases['in_hospital_death'].sum()\n",
    "death_percentage_top_cases = (death_count_top_cases / death_count_total)\n",
    "print(f'Percentage of deaths in the top {round(1 - quantile, 2) * 100}% of patients with highest Elixhauser score: {round(death_percentage_top_cases * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Patients with high Elixhauser make up {round((len(df_top_elixhauser_cases) / len(df_high_risk_cohort)) * 100, 2)} % of cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elevated Risk Surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get percentage of deaths \n",
    "death_count_total = df_high_risk_cohort['in_hospital_death'].sum()\n",
    "df_elevated_risk_cases = df_high_risk_cohort[df_high_risk_cohort['elevated_risk_surgery'] == 1]\n",
    "death_count_top_cases = df_elevated_risk_cases['in_hospital_death'].sum()\n",
    "death_percentage_top_cases = (death_count_top_cases / death_count_total)\n",
    "print(f'Percentage of deaths with elevated risk surgery patients: {round(death_percentage_top_cases * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Elevated risk patients make up {round((len(df_elevated_risk_cases) / len(df_high_risk_cohort)) * 100, 2)} % of cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine categories\n",
    "df_combined_cohorts = df_high_risk_cohort[(df_high_risk_cohort['elixhauser_van_walraven'] >= elixhauser_threshold) | (df_high_risk_cohort['elevated_risk_surgery'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get percentage of deaths \n",
    "death_count_total = df_high_risk_cohort['in_hospital_death'].sum()\n",
    "death_count_top_cases = df_combined_cohorts['in_hospital_death'].sum()\n",
    "death_percentage_top_cases = (death_count_top_cases / death_count_total)\n",
    "print(f'Percentage of deaths with either high Elixhauser or elevated risk surgery: {round(death_percentage_top_cases * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'High risk patients make up {round((len(df_combined_cohorts) / len(df_high_risk_cohort)) * 100, 2)} % of cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OP Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_eda_times = df_cohort_eda.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round to hour\n",
    "df_cohort_eda_times['hour_rounded'] = df_cohort_eda_times['op_date_time'].dt.round('H').dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequencies\n",
    "hour_counts = df_cohort_eda_times['hour_rounded'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "hour_counts.plot(kind='bar')\n",
    "plt.title('Frequency of Rounded Hours')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcomes / Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns = ['RCRI_original', 'RCRI_recalibrated']\n",
    "outcome_columns = ['MACE_30_days', 'MACE_30_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score, outcome in zip(score_columns, outcome_columns):\n",
    "    result = (df_cohort_eda.groupby(score)[outcome].sum().reset_index())\n",
    "    result.columns = [score, f'sum_of_{outcome}']\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnoses_eda.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_diagnoses_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diagnoses_eda['icd_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_diagnosed_patients = df_diagnoses_eda['case_id'].drop_duplicates()\n",
    "diagnoses_count = unique_diagnosed_patients.isin(df_cohort_eda['case_id']).sum()\n",
    "# diagnoses_count = df_cohort_eda['case_id'].isin(df_diagnoses_eda['case_id']).astype(int).sum()\n",
    "patient_count = df_cohort_eda['pat_id'].nunique()\n",
    "\n",
    "print(f'Number of patients with diagnosis: {diagnoses_count} ({round((diagnoses_count / patient_count) * 100, 2)}%)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_diagnoses_count = df_diagnoses_eda.groupby('case_id').size()\n",
    "median_case_diagnoses = case_diagnoses_count.median()\n",
    "print(f'Median number of diagnoses per case: {round(median_case_diagnoses, 4)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_prior_diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior_diagnoses_eda.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_prior_diagnoses_eda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior_diagnoses_eda['icd_code'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_prior_diagnosed_patients = df_prior_diagnoses_eda['case_id'].drop_duplicates()\n",
    "prior_diagnoses_count = df_cohort_eda['case_id'].isin(unique_prior_diagnosed_patients).astype(int).sum()\n",
    "patient_count = df_cohort_eda['pat_id'].nunique()\n",
    "\n",
    "print(f'Number of patients with prior diagnosis: {prior_diagnoses_count} ({round((prior_diagnoses_count / patient_count) * 100, 2)}%)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_prior_diagnoses_count = df_prior_diagnoses_eda.groupby('case_id').size()\n",
    "median_case_prior_diagnoses = case_prior_diagnoses_count.median()\n",
    "print(f'Median number of prior diagnoses per case: {round(median_case_prior_diagnoses, 4)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with missings\n",
    "threshold = len(df_cohort) * 0.75\n",
    "df_cohort_cleaned = df_cohort.copy().dropna(thresh=threshold, axis=1)\n",
    "removed_columns = set(df_cohort.columns) - set(df_cohort_cleaned.columns)\n",
    "print(f'Number of removed columns: {len(removed_columns)}')\n",
    "print(f'Columns that  got removed: {removed_columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation = df_cohort_cleaned.dropna(how='any')\n",
    "utils.get_amount_removed_rows(\n",
    "    initial=df_cohort_cleaned, \n",
    "    new=df_cohort_validation\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_score_columns = [\n",
    "    'RCRI_original', 'RCRI_original', \n",
    "    'CHA2DS2_VASc_original', 'CHA2DS2_VASc_original', \n",
    "    'elixhauser_van_walraven', 'elixhauser_van_walraven'\n",
    "    ]\n",
    "\n",
    "new_score_columns = [\n",
    "    'RCRI_recalibrated', 'expanded_RCRI', \n",
    "    'CHA2DS2_VASc_recalibrated', 'expanded_CHA2DS2_VASc', \n",
    "    'elixhauser_recalibrated', 'expanded_elixhauser'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for original_score, new_score in zip(original_score_columns, new_score_columns):\n",
    "    print(f'Converting: {new_score}')\n",
    "    df_cohort_validation = analysis_utils.convert_score(\n",
    "        df=df_cohort_validation, \n",
    "        original_score=original_score, \n",
    "        new_score=new_score\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome Probabilities / Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns = [\n",
    "    'RCRI_original', 'RCRI_recalibrated_converted', 'expanded_RCRI_converted', \n",
    "    'CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted', \n",
    "    'elixhauser_van_walraven', 'elixhauser_recalibrated_converted', 'expanded_elixhauser_converted'\n",
    "    ]\n",
    "\n",
    "outcome_columns = [\n",
    "    'MACE_30_days', 'MACE_30_days', 'MACE_30_days', \n",
    "    'stroke_30_days', 'stroke_30_days', 'stroke_30_days', \n",
    "    'in_hospital_death', 'in_hospital_death', 'in_hospital_death'\n",
    "    ]\n",
    "\n",
    "categorical_columns = [\n",
    "    'RCRI_original', 'RCRI_recalibrated_converted', 'expanded_RCRI_converted', \n",
    "    'CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted', \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score, outcome in zip(score_columns, outcome_columns):\n",
    "    print(f'Calculating probabilities for: {score}')\n",
    "    categorical_column = []\n",
    "    if score in categorical_columns:\n",
    "        categorical_column = [score]\n",
    "\n",
    "    analysis_utils.get_probabilities_for_cohort(\n",
    "        df=df_cohort_validation, \n",
    "        score_column=score, \n",
    "        outcome_column=outcome, \n",
    "        test_size=train_test_split, \n",
    "        categorical_columns=categorical_column\n",
    "        )\n",
    "    \n",
    "    analysis_utils.get_confidence_intervals(\n",
    "        df=df_cohort_validation, \n",
    "        score_column=score, \n",
    "        outcome_column=outcome, \n",
    "        test_size=train_test_split, \n",
    "        categorical_columns=categorical_column\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (Analysis Cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_hdl_copra_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_hdl_sap_procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_hdl_sap_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_sap_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_hdl_sap_fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_hdl_copra_diagnose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_hdl_copra_medication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_sap_movement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processed Raw Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_nicp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_npat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_cohort_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_medication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_campi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derived Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_cohort_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_prior_diagnoses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_prior_medication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_prior_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_prior_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = utils.collect_subgroups(\n",
    "    df=df_cohort_validation, \n",
    "    conditions=conditions\n",
    "    )\n",
    "subgroups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['age_above_65'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['age_below_65'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['asa_le_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['asa_gt_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['ambulatory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['inpatient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['SDA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['campus_mitte'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['campus_steglitz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=subgroups['campus_wedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(\n",
    "    df=analysis_utils.get_train_data(\n",
    "        df=df_cohort_validation, \n",
    "        test_size=train_test_split\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(\n",
    "    df=analysis_utils.get_test_data(\n",
    "        df=df_cohort_validation, \n",
    "        test_size=train_test_split\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report & Export (Analysis Cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_cohort_report = ProfileReport(df=df_cohort_validation, title='Cleaned Cohort', minimal=True)\n",
    "cleaned_cohort_report.to_file('data/cleaned-cohort_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation.to_csv(path_or_buf='data/base/cleaned_cohort_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all predictor columns, mainly used for regression and machine learning models later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing variables\n",
    "data_vars = list(df_cohort_validation.columns)\n",
    "columns_to_remove = [\n",
    "    'pat_id', 'case_id', 'admission_date_time', 'discharge_date_time', 'ops_code', 'op_date_time', 'birth_date', \n",
    "    'in_hospital_death', 'MACE_30_days', 'stroke_30_days',\n",
    "    'elixhauser_van_walraven', 'elixhauser_recalibrated', 'expanded_elixhauser', \n",
    "    'elixhauser_recalibrated_converted', 'expanded_elixhauser_converted', \n",
    "    'RCRI_original', 'RCRI_recalibrated', 'expanded_RCRI', \n",
    "    'RCRI_recalibrated_converted', 'expanded_RCRI_converted', \n",
    "    'CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated', 'expanded_CHA2DS2_VASc', \n",
    "    'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted',\n",
    "\n",
    "    'RCRI_original_probability',\n",
    "    'RCRI_original_probability_CI_lower',\n",
    "    'RCRI_original_probability_CI_upper',\n",
    "    'RCRI_recalibrated_converted_probability',\n",
    "    'RCRI_recalibrated_converted_probability_CI_lower',\n",
    "    'RCRI_recalibrated_converted_probability_CI_upper',\n",
    "    'expanded_RCRI_converted_probability',\n",
    "    'expanded_RCRI_converted_probability_CI_lower',\n",
    "    'expanded_RCRI_converted_probability_CI_upper',\n",
    "    'CHA2DS2_VASc_original_probability',\n",
    "    'CHA2DS2_VASc_original_probability_CI_lower',\n",
    "    'CHA2DS2_VASc_original_probability_CI_upper',\n",
    "    'CHA2DS2_VASc_recalibrated_converted_probability',\n",
    "    'CHA2DS2_VASc_recalibrated_converted_probability_CI_lower',\n",
    "    'CHA2DS2_VASc_recalibrated_converted_probability_CI_upper',\n",
    "    'expanded_CHA2DS2_VASc_converted_probability',\n",
    "    'expanded_CHA2DS2_VASc_converted_probability_CI_lower',\n",
    "    'expanded_CHA2DS2_VASc_converted_probability_CI_upper',\n",
    "    'elixhauser_van_walraven_probability',\n",
    "    'elixhauser_van_walraven_probability_CI_lower',\n",
    "    'elixhauser_van_walraven_probability_CI_upper',\n",
    "    'elixhauser_recalibrated_converted_probability',\n",
    "    'elixhauser_recalibrated_converted_probability_CI_lower',\n",
    "    'elixhauser_recalibrated_converted_probability_CI_upper',\n",
    "    'expanded_elixhauser_converted_probability',\n",
    "    'expanded_elixhauser_converted_probability_CI_lower',\n",
    "    'expanded_elixhauser_converted_probability_CI_upper',\n",
    "\n",
    "    'female',\n",
    "    'male',\n",
    "    'campus'\n",
    "]\n",
    "\n",
    "data_vars = [col for col in data_vars if col not in columns_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHA_variables = [\n",
    "    'female_sex', 'congestive_heart_failure_elixhauser', 'hypertension_uncomplicated_elixhauser', \n",
    "    'hypertension_complicated_elixhauser', 'diabetes_uncomplicated_elixhauser', 'diabetes_complicated_elixhauser', \n",
    "    'vascular_disease_history', 'STT_history', 'age_below_65', 'age_between_65_and_74', 'age_above_74']\n",
    "\n",
    "RCRI_variables = [\n",
    "    'elevated_risk_surgery', 'MI_history', 'congestive_heart_failure_elixhauser', \n",
    "    'CD_history', 'prior_insulin', 'prior_creatinine'\n",
    "    ]\n",
    "\n",
    "elix_variables = [col for col in df_cohort_validation.columns if col.endswith('_elixhauser')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHA_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCRI_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elix_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_outcome = 'stroke_30_days'\n",
    "MACE_outcome = 'MACE_30_days'\n",
    "death_outcome = 'in_hospital_death'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prior diagnoses and outcomes\n",
    "df_automated_mapping = pd.merge(\n",
    "    df_cohort_validation[['case_id', 'MACE_30_days', 'stroke_30_days', 'in_hospital_death']], df_prior_diagnoses[['case_id', 'icd_code']], \n",
    "    on='case_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Amount of cases: {len(df_automated_mapping)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_automated_mapping['icd_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data to only keep broader category\n",
    "df_automated_mapping['icd_code'] = df_automated_mapping['icd_code'].apply(lambda x: x[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only those that at least 1% of cases have\n",
    "icd_code_counts = df_automated_mapping['icd_code'].value_counts() # ICDs counts\n",
    "threshold = 0.01 * len(df_automated_mapping['case_id'].unique()) # threshold count\n",
    "icds_to_keep = icd_code_counts[icd_code_counts >= threshold].index # selected ICDs\n",
    "df_automated_mapping = df_automated_mapping[df_automated_mapping['icd_code'].isin(icds_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Amount of cases: {len(df_automated_mapping)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_automated_mapping['icd_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_automated_mapping = analysis_utils.get_train_data(\n",
    "    df=df_automated_mapping, \n",
    "    test_size=train_test_split, \n",
    "    calculate_proba=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important features\n",
    "selected_MACE_features = analysis_utils.get_important_features(\n",
    "    df=df_automated_mapping, \n",
    "    feature_column='icd_code', \n",
    "    outcome_column='MACE_30_days', \n",
    "    n_features=15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate column names\n",
    "selected_MACE_features_columns = []\n",
    "df_cohort_expanded_MACE = df_cohort_validation.copy()\n",
    "for feature in selected_MACE_features:\n",
    "    column_name = f'{feature}_ICD_history'\n",
    "    selected_MACE_features_columns.append(column_name)\n",
    "\n",
    "    icd_pattern = f'^{feature}'\n",
    "    df_feature = utils.extract_df_data(\n",
    "        df=df_prior_diagnoses, \n",
    "        filter_dict={'icd_code':[icd_pattern]}\n",
    "        )\n",
    "    \n",
    "    df_cohort_expanded_MACE[column_name] = df_cohort_expanded_MACE['case_id'].isin(df_feature['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHA2DS2-VASc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important features\n",
    "selected_CHA_features = analysis_utils.get_important_features(\n",
    "    df=df_automated_mapping, \n",
    "    feature_column='icd_code', \n",
    "    outcome_column='stroke_30_days', \n",
    "    n_features=15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate column names\n",
    "selected_CHA_features_columns = []\n",
    "df_cohort_expanded_CHA = df_cohort_validation.copy()\n",
    "for feature in selected_CHA_features:\n",
    "    column_name = f'{feature}_ICD_history'\n",
    "    selected_CHA_features_columns.append(column_name)\n",
    "\n",
    "    icd_pattern = f'^{feature}'\n",
    "    df_feature = utils.extract_df_data(\n",
    "        df=df_prior_diagnoses, \n",
    "        filter_dict={'icd_code':[icd_pattern]}\n",
    "        )\n",
    "    \n",
    "    df_cohort_expanded_CHA[column_name] = df_cohort_expanded_CHA['case_id'].isin(df_feature['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elixhauser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important features\n",
    "selected_elix_features = analysis_utils.get_important_features(\n",
    "    df=df_automated_mapping, \n",
    "    feature_column='icd_code', \n",
    "    outcome_column='in_hospital_death', \n",
    "    n_features=15\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate column names\n",
    "selected_elix_features_columns = []\n",
    "df_cohort_expanded_elix = df_cohort_validation.copy()\n",
    "for feature in selected_elix_features:\n",
    "    column_name = f'{feature}_ICD_history'\n",
    "    selected_elix_features_columns.append(column_name)\n",
    "\n",
    "    icd_pattern = f'^{feature}'\n",
    "    df_feature = utils.extract_df_data(\n",
    "        df=df_prior_diagnoses, \n",
    "        filter_dict={'icd_code':[icd_pattern]}\n",
    "        )\n",
    "    \n",
    "    df_cohort_expanded_elix[column_name] = df_cohort_expanded_elix['case_id'].isin(df_feature['case_id']).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cohort_validation[RCRI_variables].copy()\n",
    "y = df_cohort_validation[MACE_outcome].copy()\n",
    "\n",
    "df_RCRI_weights = analysis_utils.get_regression(\n",
    "    X=X, \n",
    "    y=y, \n",
    "    label_name='RCRI', \n",
    "    test_size=train_test_split, \n",
    "    scale_data=False, \n",
    "    use_lasso=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RCRI_weights_normalized = analysis_utils.normalize_weights(\n",
    "    df=df_RCRI_weights, \n",
    "    save_to='data/RCRI-logit-weights.csv'\n",
    "    )\n",
    "df_RCRI_weights_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanded RCRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cohort_expanded_MACE[RCRI_variables + selected_MACE_features_columns].copy()\n",
    "y = df_cohort_expanded_MACE[MACE_outcome].copy()\n",
    "\n",
    "df_expanded_RCRI_weights = analysis_utils.get_regression(\n",
    "    X=X, \n",
    "    y=y, \n",
    "    label_name='expanded RCRI', \n",
    "    test_size=train_test_split, \n",
    "    scale_data=False, \n",
    "    use_lasso=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_RCRI_weights_normalized = analysis_utils.normalize_weights(\n",
    "    df=df_expanded_RCRI_weights, \n",
    "    save_to='data/expanded-RCRI-logit-weights.csv'\n",
    "    )\n",
    "df_expanded_RCRI_weights_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHA2DS2-VASc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cohort_validation[CHA_variables].copy()\n",
    "y = df_cohort_validation[stroke_outcome].copy()\n",
    "\n",
    "df_CHA_weights = analysis_utils.get_regression(\n",
    "    X=X, \n",
    "    y=y, \n",
    "    label_name='CHA2DS2-VASc', \n",
    "    test_size=train_test_split, \n",
    "    scale_data=False, \n",
    "    use_lasso=False\n",
    "    )\n",
    "df_CHA_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CHA_weights_normalized = analysis_utils.normalize_weights(\n",
    "    df=df_CHA_weights, \n",
    "    save_to='data/CHA-logit-weights.csv'\n",
    "    )\n",
    "df_CHA_weights_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanded CHA2DS2-VASc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cohort_expanded_CHA[CHA_variables + selected_CHA_features_columns].copy()\n",
    "y = df_cohort_expanded_CHA[stroke_outcome].copy()\n",
    "\n",
    "df_expanded_CHA_weights = analysis_utils.get_regression(\n",
    "    X=X, \n",
    "    y=y, \n",
    "    label_name='Expanded CHA2DS2-VASc', \n",
    "    test_size=train_test_split, \n",
    "    scale_data=False, \n",
    "    use_lasso=False\n",
    "    )\n",
    "df_expanded_CHA_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_CHA_weights_normalized = analysis_utils.normalize_weights(\n",
    "    df=df_expanded_CHA_weights, \n",
    "    save_to='data/expanded-CHA-logit-weights.csv'\n",
    "    )\n",
    "df_expanded_CHA_weights_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elixhauser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cohort_validation[elix_variables].copy()\n",
    "y = df_cohort_validation[death_outcome].copy()\n",
    "\n",
    "df_elix_weights = analysis_utils.get_regression(\n",
    "    X=X, \n",
    "    y=y, \n",
    "    label_name='Elixhauser', \n",
    "    test_size=train_test_split, \n",
    "    scale_data=False, \n",
    "    use_lasso=False\n",
    "    )\n",
    "df_elix_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elix_weights_normalized = analysis_utils.normalize_weights(\n",
    "    df=df_elix_weights, \n",
    "    save_to='data/elixhauser-logit-weights.csv'\n",
    "    )\n",
    "df_elix_weights_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanded Elixhauser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_elix_features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cohort_expanded_elix[elix_variables + selected_elix_features_columns].copy()\n",
    "y = df_cohort_expanded_elix[death_outcome].copy()\n",
    "\n",
    "df_expanded_elix_weights = analysis_utils.get_regression(\n",
    "    X=X, \n",
    "    y=y, \n",
    "    label_name='Expanded Elixhauser', \n",
    "    test_size=train_test_split, \n",
    "    scale_data=False, \n",
    "    use_lasso=False\n",
    "    )\n",
    "df_expanded_elix_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_elix_weights_normalized = analysis_utils.normalize_weights(\n",
    "    df=df_expanded_elix_weights, \n",
    "    save_to='data/expanded-elixhauser-logit-weights.csv'\n",
    "    )\n",
    "df_expanded_elix_weights_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning [WIP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "variables = RCRI_variables + list(df_expanded_RCRI_weights[df_expanded_RCRI_weights['feature'] != 'const']['feature'])\n",
    "outcome = MACE_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "X_train, X_test, y_train, y_test = ml_utils.preprocessing(\n",
    "    df=df_cohort_expanded_MACE, \n",
    "    variables=variables, \n",
    "    outcome=outcome, \n",
    "    scale=True, \n",
    "    resample=True, \n",
    "    test_size=train_test_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect data\n",
    "ml_utils.get_eda_metrics(\n",
    "    X_train=X_train, \n",
    "    X_test=X_test, \n",
    "    y_train=y_train, \n",
    "    y_test=y_test, \n",
    "    variables=variables, \n",
    "    outcome=outcome\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare, train, and evaluate model\n",
    " \n",
    "class_weights = ml_utils.get_class_weights(y_train=y_train)\n",
    "\n",
    "model, criterion, optimizer = ml_utils.get_model(\n",
    "    features=len(variables), \n",
    "    class_weights_tensor=class_weights, \n",
    "    selected_model=ml_utils.Model.CUSTOM\n",
    "    )\n",
    "\n",
    "ml_utils.train(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    model=model, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    epochs=800\n",
    "    )\n",
    "\n",
    "ml_utils.evaluate(\n",
    "    model=model, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "ml_utils.export_model_state(\n",
    "    model=model, \n",
    "    path='data/ml/', \n",
    "    name='custom-model_v1'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data = df_cohort_expanded_MACE[\n",
    "    RCRI_variables + list(df_expanded_RCRI_weights[df_expanded_RCRI_weights['feature'] != 'const']['feature']) + [MACE_outcome]\n",
    "    ].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and test models\n",
    "autoML_model = ml_utils.get_autoML(\n",
    "    data=data, \n",
    "    target=MACE_outcome\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroups = utils.collect_subgroups(\n",
    "    df=df_cohort_validation, \n",
    "    conditions=conditions\n",
    "    )\n",
    "subgroups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_utils.validate_score(\n",
    "    df=df_cohort_validation, \n",
    "    score_columns=['RCRI_original', 'RCRI_recalibrated_converted', 'expanded_RCRI_converted'], \n",
    "    outcome_column='MACE_30_days', \n",
    "    test_size=train_test_split, \n",
    "    dca_y_limits=[-0.002, 0.010], \n",
    "    categorical_columns=['RCRI_original', 'RCRI_recalibrated', 'expanded_RCRI']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_utils.evaluate_subgroups(\n",
    "    subgroups=subgroups, \n",
    "    score_columns=['RCRI_original', 'RCRI_recalibrated_converted', 'expanded_RCRI_converted'], \n",
    "    outcome_column='MACE_30_days', \n",
    "    test_size=train_test_split, \n",
    "    categorical_columns=['RCRI_original', 'RCRI_recalibrated_converted', 'expanded_RCRI_converted']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHA2DS2-VASc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort for CHA2DS2-VASc\n",
    "df_cohort_validation_AF = df_cohort_validation[df_cohort_validation['AF_history'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_utils.validate_score(\n",
    "    df=df_cohort_validation, \n",
    "    score_columns=['CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted'], \n",
    "    outcome_column='stroke_30_days', \n",
    "    test_size=train_test_split, \n",
    "    dca_y_limits=[-0.002, 0.010], \n",
    "    categorical_columns=['CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_utils.evaluate_subgroups(\n",
    "    subgroups=subgroups, \n",
    "    score_columns=['CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted'], \n",
    "    outcome_column='stroke_30_days', \n",
    "    test_size=train_test_split, \n",
    "    categorical_columns=['CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elixhauser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_utils.validate_score(\n",
    "    df=df_cohort_validation, \n",
    "    score_columns=['elixhauser_van_walraven', 'elixhauser_recalibrated_converted', 'expanded_elixhauser_converted'], \n",
    "    outcome_column='in_hospital_death', \n",
    "    test_size=train_test_split, \n",
    "    dca_y_limits=[-0.002, 0.002], \n",
    "    dca_thresholds=np.arange(0, 0.05, 0.01), \n",
    "    categorical_columns=['elixhauser_van_walraven', 'elixhauser_recalibrated_converted', 'expanded_elixhauser_converted']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_utils.evaluate_subgroups(\n",
    "    subgroups=subgroups, \n",
    "    score_columns=['elixhauser_van_walraven', 'elixhauser_recalibrated_converted', 'expanded_elixhauser_converted'], \n",
    "    outcome_column='in_hospital_death', \n",
    "    test_size=train_test_split, \n",
    "    categorical_columns=['elixhauser_van_walraven', 'elixhauser_recalibrated_converted', 'expanded_elixhauser_converted']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_sample = df_cohort.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_conditions = [\n",
    "    (lambda row: row['campus'] == 'S', 'sample_base'),  # campus\n",
    "    (lambda row: pd.isna(row['asa_status']), 'sample_criteria_a'), # missings\n",
    "    (lambda row: (row['AF_history'] == 1), 'sample_criteria_b'), # prior\n",
    "    (lambda row: (row['stroke_30_days'] == 1), 'sample_criteria_c'), # post\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_sample = utils.create_subgroups(\n",
    "    df=df_cohort_sample, \n",
    "    conditions=selection_conditions\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all from campus\n",
    "df_base = df_cohort_sample[df_cohort_sample['sample_base'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all with sample criteria\n",
    "df_a = df_base[df_base['sample_criteria_a'] == 1]\n",
    "df_b = df_base[df_base['sample_criteria_b'] == 1]\n",
    "df_c = df_base[df_base['sample_criteria_c'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select with sample criteria\n",
    "sample_a = df_a.sample(n=5, random_state=42)\n",
    "sample_b = df_b.sample(n=5, random_state=42)\n",
    "sample_c = df_c.sample(n=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select without sample criteria\n",
    "remaining_cases = df_base.drop(sample_a.index).drop(sample_b.index).drop(sample_c.index).sample(n=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group all\n",
    "df_selected = pd.concat([sample_a, sample_b, sample_c, remaining_cases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect\n",
    "utils.get_eda_metrics(df=df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "df_selected.to_csv(path_or_buf='data/cohort_data_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build report\n",
    "cohort_sample_report = ProfileReport(df=df_selected, title='Cohort Sample', minimal=True)\n",
    "cohort_sample_report.to_file('data/cohort_samle_report.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
