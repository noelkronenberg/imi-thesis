{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corr_utils.covariate as utils\n",
    "import corr_utils.extraction as extraction_utils\n",
    "import corr_utils.analysis as analysis_utils\n",
    "import corr_utils.ml as ml_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from dcurves import dca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableone import TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import contextlib\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(utils)\n",
    "reload(analysis_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalculate_probas = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation = pd.read_csv('data/base/240920_cleaned_cohort_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if recalculate_probas:\n",
    "\n",
    "    score_columns = [\n",
    "        'RCRI_original', 'RCRI_recalibrated_converted', 'expanded_RCRI_converted', \n",
    "        'CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted', \n",
    "        'elixhauser_van_walraven', 'elixhauser_recalibrated_converted', 'expanded_elixhauser_converted'\n",
    "        ]\n",
    "\n",
    "    outcome_columns = [\n",
    "        'MACE_30_days', 'MACE_30_days', 'MACE_30_days', \n",
    "        'stroke_30_days', 'stroke_30_days', 'stroke_30_days', \n",
    "        'in_hospital_death', 'in_hospital_death', 'in_hospital_death'\n",
    "        ]\n",
    "\n",
    "    categorical_columns = [\n",
    "        'RCRI_original', 'RCRI_recalibrated_converted', 'expanded_RCRI_converted', \n",
    "        'CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted', \n",
    "        ]\n",
    "\n",
    "    proba_columns_to_drop = [f'{score_column}_probability' for score_column in score_columns]\n",
    "    df_cohort_validation = df_cohort_validation.drop(columns=proba_columns_to_drop)\n",
    "\n",
    "    upper_columns_to_drop = [f'{score_column}_probability_CI_upper' for score_column in score_columns]\n",
    "    df_cohort_validation = df_cohort_validation.drop(columns=upper_columns_to_drop)\n",
    "\n",
    "    lower_columns_to_drop = [f'{score_column}_probability_CI_lower' for score_column in score_columns]\n",
    "    df_cohort_validation = df_cohort_validation.drop(columns=lower_columns_to_drop)\n",
    "\n",
    "    for score, outcome in zip(score_columns, outcome_columns):\n",
    "        print(f'Calculating probabilities for: {score}')\n",
    "        categorical_column = []\n",
    "        if score in categorical_columns:\n",
    "            categorical_column = [score]\n",
    "\n",
    "        analysis_utils.get_probabilities_for_cohort(\n",
    "            df=df_cohort_validation, \n",
    "            score_column=score, \n",
    "            outcome_column=outcome, \n",
    "            test_size=train_test_split, \n",
    "            categorical_columns=categorical_column\n",
    "            )\n",
    "        \n",
    "        analysis_utils.get_confidence_intervals(\n",
    "            df=df_cohort_validation, \n",
    "            score_column=score, \n",
    "            outcome_column=outcome, \n",
    "            test_size=train_test_split, \n",
    "            categorical_columns=categorical_column\n",
    "            )\n",
    "\n",
    "    df_cohort_validation.to_csv(path_or_buf='data/base/240920_cleaned_cohort_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_cohort_validation.columns:\n",
    "    if 'date' in col.lower() or 'time' in col.lower():\n",
    "        df_cohort_validation[col] = pd.to_datetime(df_cohort_validation[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (lambda row: row['female_sex'] == 1, 'female'),\n",
    "    (lambda row: row['female_sex'] == 0, 'male'),\n",
    "    (lambda row: row['campus'] == 'M', 'campus_mitte'),\n",
    "    (lambda row: row['campus'] == 'S', 'campus_steglitz'),\n",
    "    (lambda row: row['campus'] == 'W', 'campus_wedding'),\n",
    "    (lambda row: row['age_during_op'] > 65, 'age_above_65'),\n",
    "    (lambda row: row['asa_status'] <= 2, 'asa_le_2'),\n",
    "    (lambda row: row['asa_status'] > 2, 'asa_gt_2'),\n",
    "    (lambda row: row['admission_date_time'].day == row['op_date_time'].day == row['discharge_date_time'].day, 'ambulatory'),\n",
    "    (lambda row: row['admission_date_time'].day < row['op_date_time'].day < row['discharge_date_time'].day, 'inpatient'),\n",
    "    (lambda row: row['admission_date_time'].day == row['op_date_time'].day < row['discharge_date_time'].day, 'SDA')\n",
    "]\n",
    "\n",
    "subgroups = utils.collect_subgroups(\n",
    "    df=df_cohort_validation, \n",
    "    conditions=conditions\n",
    "    )\n",
    "subgroups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.get_eda_metrics(df=df_cohort_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_cohort_validation.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset\n",
    "pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.color'] = 'lightgrey'\n",
    "plt.rcParams['grid.linestyle'] = '-'\n",
    "plt.rcParams['grid.linewidth'] = 0.6\n",
    "plt.rcParams['axes.grid.axis'] = 'both'\n",
    "plt.rcParams['axes.edgecolor'] = 'lightgrey'\n",
    "\n",
    "plt.rcParams['legend.frameon'] = True\n",
    "plt.rcParams['legend.framealpha'] = 1\n",
    "plt.rcParams['legend.facecolor'] = 'white'\n",
    "plt.rcParams['legend.edgecolor'] = 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_columns_all = [\n",
    "    'RCRI_original', \n",
    "    'RCRI_recalibrated_converted',\n",
    "    'expanded_RCRI_converted',\n",
    "    'CHA2DS2_VASc_original', \n",
    "    'CHA2DS2_VASc_recalibrated_converted',\n",
    "    'expanded_CHA2DS2_VASc_converted', \n",
    "    'elixhauser_van_walraven',\n",
    "    'elixhauser_recalibrated_converted'\n",
    "]\n",
    "\n",
    "sns_red = sns.color_palette(\"hls\", 8)[0]\n",
    "sns_blue = sns.color_palette(\"hls\", 8)[5]\n",
    "sns_green = blue = sns.color_palette(\"hls\", 8)[2]\n",
    "\n",
    "lightened_red = sns.light_palette(sns_red, n_colors=5, reverse=False)[2] \n",
    "lightest_red = sns.light_palette(sns_red, n_colors=5, reverse=False)[1] \n",
    "\n",
    "lightened_blue = sns.light_palette(sns_blue, n_colors=5, reverse=False)[2] \n",
    "lightest_blue = sns.light_palette(sns_blue, n_colors=5, reverse=False)[1] \n",
    "\n",
    "lightened_green= sns.light_palette(sns_green, n_colors=5, reverse=False)[2] \n",
    "lightest_green = sns.light_palette(sns_green, n_colors=5, reverse=False)[1] \n",
    "\n",
    "color_map = {\n",
    "    'RCRI_original': sns_red,\n",
    "    'RCRI (original)': sns_red,\n",
    "    'RCRI_recalibrated_converted': lightened_red,\n",
    "    'RCRI (recalibrated, converted)': lightened_red,\n",
    "    'expanded_RCRI_converted': lightest_red,\n",
    "    'RCRI (expanded, converted)': lightest_red,\n",
    "    'MACE': sns_red,\n",
    "    'MACE_30_days_count': sns_red,\n",
    "\n",
    "    'CHA2DS2_VASc_original': sns_blue,\n",
    "    'CHA2DS2-VASc (original)': sns_blue,\n",
    "    'CHA2DS2_VASc_recalibrated_converted': lightened_blue,\n",
    "    'CHA2DS2-VASc (recalibrated, converted)': lightened_blue, \n",
    "    'expanded_CHA2DS2_VASc_converted': lightest_blue, \n",
    "    'CHA2DS2-VASc (expanded, converted)': lightest_blue, \n",
    "    'Stroke': sns_blue,\n",
    "    'stroke_30_days_count': sns_blue,\n",
    "\n",
    "    'elixhauser_van_walraven': sns_green,\n",
    "    'Elixhauser (van Walraven)': sns_green,\n",
    "    'elixhauser_recalibrated_converted': lightened_green,\n",
    "    'Elixhauser (recalibrated, converted)': lightest_green, \n",
    "    'In-Hospital Mortality': sns_green,\n",
    "    'in_hospital_death_count': sns_green,\n",
    "\n",
    "    'all': 'lightgrey',\n",
    "    'none': 'black'\n",
    "}\n",
    "\n",
    "palette = sns.color_palette([color_map[score] for score in score_columns_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "campus_color_map = {\n",
    "    'Mitte': '#4d4d4d', \n",
    "    'Steglitz': '#7f7f7f',\n",
    "    'Wedding': '#bfbfbf'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'figures/data quality/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_counts = df_cohort_validation['op_date_time'].dt.year.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(yearly_counts.index, yearly_counts.values, color='black')\n",
    "plt.xlabel('Year of Surgery')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(yearly_counts.index) \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{path}OP-years.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation['hour_rounded'] = df_cohort_validation['op_date_time'].dt.round('H').dt.hour\n",
    "hour_counts = df_cohort_validation['hour_rounded'].value_counts().sort_index()\n",
    "df_cohort_validation.drop(columns=['hour_rounded'], inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "hour_counts.plot(kind='bar', color='black')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{path}OP-hours.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of Stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_dates = pd.to_datetime(df_cohort_validation['admission_date_time'])\n",
    "discharge_dates = pd.to_datetime(df_cohort_validation['discharge_date_time'])\n",
    "length_of_stay = discharge_dates - admission_dates\n",
    "length_of_stay = length_of_stay.fillna(pd.NaT)\n",
    "\n",
    "df_length_of_stay = pd.DataFrame({\n",
    "    'case_id': df_cohort_validation['case_id'],\n",
    "    'length_of_stay': length_of_stay\n",
    "})\n",
    "\n",
    "utils.get_eda_metrics(df=df_length_of_stay).to_csv(f'{path}length-of-stay.csv', index=False)\n",
    "utils.get_eda_metrics(df=df_length_of_stay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation['year'] = df_cohort_validation['admission_date_time'].dt.year\n",
    "\n",
    "yearly_data = df_cohort_validation.groupby('year').agg({\n",
    "    'stroke_30_days': 'sum',\n",
    "    'MACE_30_days': 'sum',\n",
    "    'in_hospital_death': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# reference: https://www.geeksforgeeks.org/python-pandas-melt/\n",
    "yearly_data_long = yearly_data.melt(id_vars='year', \n",
    "                                      value_vars=['stroke_30_days', 'MACE_30_days', 'in_hospital_death'],\n",
    "                                      var_name='Outcome', value_name='Count')\n",
    "\n",
    "df_cohort_validation.drop(columns=['year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_labels = {\n",
    "    'stroke_30_days': 'Stroke',\n",
    "    'MACE_30_days': 'MACE',\n",
    "    'in_hospital_death': 'In-Hospital Mortality'\n",
    "}\n",
    "\n",
    "yearly_data_long['Outcome'] = yearly_data_long['Outcome'].map(outcome_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(data=yearly_data_long, x='year', y='Count', hue='Outcome', \n",
    "             palette=[color_map['Stroke'], color_map['MACE'], color_map['In-Hospital Mortality']],\n",
    "             marker='o')\n",
    "\n",
    "plt.xticks(ticks=yearly_data['year'], labels=yearly_data['year'].astype(int))\n",
    "plt.xlabel('Year of Admission')\n",
    "plt.ylabel('Outcome Count')\n",
    "plt.legend(title='')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{path}outcomes-years.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation['year'] = df_cohort_validation['admission_date_time'].dt.year\n",
    "\n",
    "yearly_data = df_cohort_validation.groupby('year').agg(\n",
    "    total_surgeries=('case_id', 'count'),\n",
    "    MACE_30_days_count=('MACE_30_days', 'sum'),\n",
    "    stroke_30_days_count=('stroke_30_days', 'sum'),\n",
    "    in_hospital_death_count=('in_hospital_death', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "df_cohort_validation.drop(columns=['year'], inplace=True)\n",
    "\n",
    "yearly_data['MACE_proportion'] = yearly_data['MACE_30_days_count'] / yearly_data['total_surgeries']\n",
    "yearly_data['stroke_proportion'] = yearly_data['stroke_30_days_count'] / yearly_data['total_surgeries']\n",
    "yearly_data['death_proportion'] = yearly_data['in_hospital_death_count'] / yearly_data['total_surgeries']\n",
    "\n",
    "yearly_data_long = pd.melt(yearly_data, id_vars=['year', 'total_surgeries'], \n",
    "                      value_vars=['MACE_proportion', 'stroke_proportion', 'death_proportion'],\n",
    "                      var_name='Outcome', value_name='Proportion')\n",
    "\n",
    "outcome_labels = {\n",
    "    'MACE_proportion': 'MACE',\n",
    "    'stroke_proportion': 'Stroke',\n",
    "    'death_proportion': 'In-Hospital Mortality'\n",
    "}\n",
    "yearly_data_long['Outcome'] = yearly_data_long['Outcome'].map(outcome_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "scatter_plot = sns.scatterplot(data=yearly_data_long, \n",
    "                                x='total_surgeries', \n",
    "                                y='Proportion', \n",
    "                                hue='Outcome', \n",
    "                                palette=color_map, \n",
    "                                s=25)\n",
    "\n",
    "for outcome in yearly_data_long['Outcome'].unique():\n",
    "    outcome_data = yearly_data_long[yearly_data_long['Outcome'] == outcome]\n",
    "    line_color = color_map[outcome]\n",
    "    sns.regplot(data=outcome_data, \n",
    "                x='total_surgeries', \n",
    "                y='Proportion', \n",
    "                scatter=False,\n",
    "                label=None, \n",
    "                ci=95,\n",
    "                order=1, # linear regression\n",
    "                line_kws={'linewidth': 1},\n",
    "                color=line_color)\n",
    "\n",
    "plt.xlabel('Total Surgeries', fontsize=12)\n",
    "plt.ylabel('Proportion of Outcomes', fontsize=12)\n",
    "plt.legend(title='', loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(f'{path}outcomes-proportions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "scatter_plot = sns.scatterplot(data=yearly_data_long, \n",
    "                                x='year', \n",
    "                                y='Proportion', \n",
    "                                hue='Outcome', \n",
    "                                palette=color_map, \n",
    "                                s=25)\n",
    "\n",
    "for outcome in yearly_data_long['Outcome'].unique():\n",
    "    outcome_data = yearly_data_long[yearly_data_long['Outcome'] == outcome]\n",
    "    line_color = color_map[outcome]\n",
    "    sns.regplot(data=outcome_data, \n",
    "                x='year', \n",
    "                y='Proportion', \n",
    "                scatter=False,\n",
    "                label=None, \n",
    "                ci=95,\n",
    "                order=1, # linear regression\n",
    "                line_kws={'linewidth': 1},\n",
    "                color=line_color)\n",
    "\n",
    "plt.xticks(ticks=outcome_data['year'], labels=outcome_data['year'].astype(int))\n",
    "plt.xlabel('Years', fontsize=12)\n",
    "plt.ylabel('Proportion of Outcomes', fontsize=12)\n",
    "plt.legend(title='', loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(f'{path}outcomes-years-proportions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACE_correlation = yearly_data['total_surgeries'].corr(yearly_data['MACE_proportion'], method='spearman')\n",
    "stroke_correlation = yearly_data['total_surgeries'].corr(yearly_data['stroke_proportion'], method='spearman')\n",
    "death_correlation = yearly_data['total_surgeries'].corr(yearly_data['death_proportion'], method='spearman')\n",
    "\n",
    "print(f'Correlation between total surgeries and MACE proportion: {MACE_correlation}')\n",
    "print(f'Correlation between total surgeries and stroke proportion: {stroke_correlation}')\n",
    "print(f'Correlation between total surgeries and in-hospital mortality proportion: {death_correlation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACE_correlation = yearly_data['year'].corr(yearly_data['MACE_proportion'], method='spearman')\n",
    "stroke_correlation = yearly_data['year'].corr(yearly_data['stroke_proportion'], method='spearman')\n",
    "death_correlation = yearly_data['year'].corr(yearly_data['death_proportion'], method='spearman')\n",
    "\n",
    "print(f'Correlation between total surgeries and MACE proportion over the years: {MACE_correlation}')\n",
    "print(f'Correlation between total surgeries and stroke proportion over the years: {stroke_correlation}')\n",
    "print(f'Correlation between total surgeries and in-hospital mortality proportion over the years: {death_correlation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COPRA Transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, error = extraction_utils.connect_impala(\n",
    "    remote_hostname='hdl-edge01.charite.de', \n",
    "    username='nokr10'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = (\n",
    "    'c_var_name IN (\"BEH_ANAE_ASA_STATUS\", \"Risiko_ASA\", \"Behandlung_Anae_Praemed_ASA_Status\", \"Praemedikation_ASA_Status\")' # ASA status\n",
    ")\n",
    "\n",
    "df_hdl_copra_hierarchy = extraction_utils.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_copra6_hierarchy_v2', \n",
    "    conn=conn, \n",
    "    where=where + \" AND CAST( `_hdl_loadstamp` AS DATE) <= '2024-09-05'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchy = utils.extract_df_data(\n",
    "    df=df_hdl_copra_hierarchy, \n",
    "    col_dict={\n",
    "        'c_falnr':'case_id', \n",
    "        'c_var_name':'variable', \n",
    "        'c_value':'value', \n",
    "        'c_var_timestamp':'date_time'\n",
    "        },\n",
    "    remove_prefix=False,\n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['date_time']:\n",
    "    df_hierarchy[f'{column}'] = pd.to_datetime(df_hierarchy[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract by priority\n",
    "df_asa_status = utils.extract_by_priority(\n",
    "    df=df_hierarchy, \n",
    "    column='variable', \n",
    "    priority_order=[\n",
    "        'BEH_ANAE_ASA_STATUS', 'Risiko_ASA', 'Behandlung_Anae_Praemed_ASA_Status', \n",
    "        'Praemedikation_ASA_Status'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asa_status = utils.handle_duplicates(\n",
    "    df=df_asa_status, \n",
    "    column='case_id', \n",
    "    drop_duplicates=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_asa_status.rename(columns={'value': 'asa_status'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique value counts\n",
    "df_asa_status['asa_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all numbers\n",
    "\n",
    "def extract_number(value):\n",
    "    number = ''.join(filter(str.isdigit, str(value)))\n",
    "    return int(number) if number else np.nan\n",
    "\n",
    "df_asa_status['asa_status'] = df_asa_status['asa_status'].apply(extract_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check (new) unique value counts\n",
    "df_asa_status['asa_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-numerics\n",
    "df_asa_status_cleaned = df_asa_status.dropna(subset=['asa_status']) \n",
    "utils.get_amount_removed_rows(\n",
    "    initial=df_asa_status, \n",
    "    new=df_asa_status_cleaned\n",
    "    )\n",
    "df_asa_status = df_asa_status_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asa_status = utils.exclude_rows(\n",
    "    df=df_asa_status, \n",
    "    column='asa_status', \n",
    "    items=[1.0], \n",
    "    filter_operator=operator.le\n",
    "    ) # ge = greater or equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asa_status = utils.exclude_rows(\n",
    "    df=df_asa_status, \n",
    "    column='asa_status', \n",
    "    items=[7.0], \n",
    "    filter_operator=operator.ge\n",
    "    ) # ge = greater or equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check (new) unique value counts\n",
    "df_asa_status['asa_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort_validation_copra = pd.merge(df_cohort_validation, df_asa_status[['case_id', 'asa_status']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation_copra['asa_status'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asa_variables = ['BEH_ANAE_ASA_STATUS', 'Risiko_ASA', 'Behandlung_Anae_Praemed_ASA_Status', 'Praemedikation_ASA_Status']\n",
    "df_filtered = df_hierarchy[df_hierarchy['variable'].isin(asa_variables)]\n",
    "df_grouped = df_filtered.groupby('case_id')['variable'].nunique()\n",
    "df_more_than_one = df_grouped[df_grouped > 1]\n",
    "num_patients = df_more_than_one.count()\n",
    "\n",
    "print(f'Number of (total) patients with more than one variable present: {num_patients}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df_grouped.value_counts().sort_index()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.rename(columns={\n",
    "    'variable': 'asa_status_variable',\n",
    "    'date_time': 'asa_status_date_time'\n",
    "    },\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation_copra_temp = pd.merge(df_cohort_validation_copra, df_filtered[['case_id', 'asa_status_variable', 'asa_status_date_time']], on='case_id', how='left')\n",
    "len(df_cohort_validation_copra_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_cohort_validation_copra_temp.groupby('case_id')['asa_status_variable'].nunique()\n",
    "df_more_than_one = df_grouped[df_grouped > 1]\n",
    "num_patients = df_more_than_one.count()\n",
    "\n",
    "print(f'Number of patients (in cohort) with more than one variable present: {num_patients} ({num_patients/len(df_cohort_validation)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get original study cohort \n",
    "df_cohort_validation_copra_temp = utils.handle_duplicates(\n",
    "    df = df_cohort_validation_copra_temp, \n",
    "    column='case_id', \n",
    "    drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove those without ASA\n",
    "df_cohort_validation_copra_temp_cleaned = utils.exclude_rows(\n",
    "    df=df_cohort_validation_copra_temp, \n",
    "    column='asa_status', \n",
    "    items=[np.nan], \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cases that are outside of stay\n",
    "\n",
    "conditions = [\n",
    "    (lambda row: (row['admission_date_time'] < row['asa_status_date_time']) and (row['asa_status_date_time'] < row['discharge_date_time']), 'ASA_between_stay')\n",
    "]\n",
    "\n",
    "df_cohort_cleaned = utils.create_subgroups(\n",
    "    df=df_cohort_validation_copra_temp_cleaned, \n",
    "    conditions=conditions\n",
    "    )\n",
    "\n",
    "df_cohort_cleaned_removed = utils.exclude_rows(\n",
    "    df=df_cohort_cleaned, \n",
    "    column='ASA_between_stay', \n",
    "    items=[0]\n",
    "    )\n",
    "df_cohort_cleaned_removed.drop(columns=['ASA_between_stay'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation_copra['year'] = df_cohort_validation_copra['admission_date_time'].dt.year\n",
    "\n",
    "yearly_asa_status = df_cohort_validation_copra.groupby('year').agg(\n",
    "    total_records=('asa_status', 'size'),\n",
    "    missing_count=('asa_status', lambda x: x.isna().sum())\n",
    ").reset_index()\n",
    "\n",
    "yearly_asa_status['missing_percentage'] = (yearly_asa_status['missing_count'] / yearly_asa_status['total_records']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=yearly_asa_status, x='year', y='missing_percentage', marker='o', color='black')\n",
    "plt.xlabel('Year of Admission')\n",
    "plt.ylabel('Proportion of Missing ASA Status (%)')\n",
    "plt.title('Proportion of Missing ASA Status Over the Years')\n",
    "plt.xticks(ticks=yearly_asa_status['year'], labels=yearly_asa_status['year'].astype(int))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{path}copra-missing-overall.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation_copra['year'] = df_cohort_validation_copra['admission_date_time'].dt.year\n",
    "\n",
    "campus_map = {\n",
    "    'M': 'Mitte',\n",
    "    'S': 'Steglitz',\n",
    "    'W': 'Wedding'\n",
    "}\n",
    "\n",
    "df_cohort_validation_copra['campus'] = df_cohort_validation_copra['campus'].map(campus_map)\n",
    "\n",
    "yearly_campus_asa_status = df_cohort_validation_copra.groupby(['year', 'campus']).agg(\n",
    "    total_records=('asa_status', 'size'), \n",
    "    missing_count=('asa_status', lambda x: x.isna().sum())\n",
    ").reset_index()\n",
    "\n",
    "yearly_campus_asa_status['missing_percentage'] = (yearly_campus_asa_status['missing_count'] / yearly_campus_asa_status['total_records']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "sns.lineplot(data=yearly_campus_asa_status, x='year', y='missing_percentage', hue='campus', palette=campus_color_map, marker='o')\n",
    "plt.xlabel('Year of Admission')\n",
    "plt.ylabel('Proportion of Missing ASA Status (%)')\n",
    "plt.legend(title='')\n",
    "plt.xticks(ticks=yearly_campus_asa_status['year'].unique(), labels=yearly_campus_asa_status['year'].unique().astype(int))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{path}copra-missing-campus.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = train_test_split\n",
    "number_bins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'RCRI_original', \n",
    "    'RCRI_recalibrated_converted',\n",
    "    'expanded_RCRI_converted',\n",
    "    'CHA2DS2_VASc_original',\n",
    "    'CHA2DS2_VASc_recalibrated_converted',\n",
    "    'expanded_CHA2DS2_VASc_converted', \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://docs.python.org/3/library/contextlib.html\n",
    "@contextlib.contextmanager\n",
    "def suppress_prints():\n",
    "    with io.StringIO() as buf, contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf): # reference: https://stackoverflow.com/a/22434594\n",
    "        plt.ioff()\n",
    "        yield "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(df:pd.DataFrame, score_columns:list, outcome_columns:list, score_names:list, outcome_names:list, test_split:float, path:str):\n",
    "\n",
    "    \"\"\"\n",
    "    data | BS & BSS\n",
    "    \"\"\"\n",
    "    \n",
    "    bs_results = []\n",
    "    bss_results = []\n",
    "\n",
    "    for score, outcome, score_name, outcome_name in zip(score_columns, outcome_columns, score_names, outcome_names):\n",
    "\n",
    "        bs_result = analysis_utils.get_brier(\n",
    "            df=df, \n",
    "            score_column=score, \n",
    "            outcome_column=outcome, \n",
    "            test_size=test_split\n",
    "            )\n",
    "        \n",
    "        bs_results.append({'Score': score_name, 'Outcome': outcome_name, 'BS': bs_result})\n",
    "\n",
    "        bss_result = analysis_utils.get_brier_skill(\n",
    "            df=df, \n",
    "            score_column=score, \n",
    "            outcome_column=outcome, \n",
    "            test_size=test_split\n",
    "            )\n",
    "\n",
    "        bss_results.append({'Score': score_name, 'Outcome': outcome_name, 'BSS': bss_result})\n",
    "        print('')\n",
    "        \n",
    "    df_bs = pd.DataFrame(bs_results)\n",
    "    # print(df_bs)\n",
    "\n",
    "    df_bss = pd.DataFrame(bss_results)\n",
    "    # print(df_bss)\n",
    "    \n",
    "    \"\"\"\n",
    "    plotting | BSS\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=df_bss, x='Score', y='BSS', hue='Outcome', palette=color_map)\n",
    "\n",
    "    plt.ylabel('Brier Skill Score')\n",
    "    plt.xlabel('Risk Scores')\n",
    "\n",
    "    plt.legend(title='')\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    export | BSS (Figure)\n",
    "    \"\"\"\n",
    "\n",
    "    plt.savefig(f'{path}_BSS.png')\n",
    "\n",
    "    \"\"\"\n",
    "    plotting | BS\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=df_bs, x='Score', y='BS', hue='Outcome', palette=color_map)\n",
    "\n",
    "    plt.ylabel('Brier Score')\n",
    "    plt.xlabel('Risk Scores')\n",
    "\n",
    "    plt.legend(title='')\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    export | BS (Figure)\n",
    "    \"\"\" \n",
    "\n",
    "    plt.savefig(f'{path}_BS.png')\n",
    "\n",
    "    \"\"\"\n",
    "    export | BS & BSS (DataFrames)\n",
    "    \"\"\"\n",
    "\n",
    "    df_bs.to_csv(f'{path}_BS.csv', index=False)\n",
    "    df_bss.to_csv(f'{path}_BSS.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration(df:pd.DataFrame, score_columns:list, outcome_columns:list, score_names:list, test_split:float, path:str):\n",
    "\n",
    "    \"\"\"\n",
    "    data\n",
    "    \"\"\"\n",
    "\n",
    "    # reference: https://github.com/scikit-learn/scikit-learn/discussions/24123\n",
    "    def calibration_curve_counts(y_prob, n_bins):\n",
    "        bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "        binids = np.searchsorted(bins[1:-1], y_prob) \n",
    "        bin_total = np.bincount(binids, minlength=len(bins)) \n",
    "        nonzero = bin_total != 0\n",
    "        return bin_total[nonzero]\n",
    "\n",
    "    calibration_results = []\n",
    "\n",
    "    for score, outcome, score_name in zip(score_columns, outcome_columns, score_names):\n",
    "\n",
    "        df_test = analysis_utils.get_test_data(\n",
    "            df=df, \n",
    "            score_column=score, \n",
    "            outcome_column=outcome, \n",
    "            test_size=test_split\n",
    "            )  \n",
    "\n",
    "        observed = df_test[outcome]\n",
    "        predicted = df_test[f'{score}_probability']\n",
    "\n",
    "        prob_true, prob_pred = calibration_curve(observed, predicted, n_bins=number_bins)\n",
    "        counts = calibration_curve_counts(predicted, n_bins=number_bins)\n",
    "\n",
    "        # filter out nan\n",
    "        if not (np.isnan(prob_pred).any() or np.isnan(prob_true).any()): \n",
    "            model = LinearRegression().fit(np.array(prob_pred).reshape(-1, 1), prob_true)\n",
    "            slope = model.coef_[0]\n",
    "            intercept = model.intercept_\n",
    "        else:\n",
    "            slope = np.nan\n",
    "            intercept = np.nan\n",
    "\n",
    "        calibration_results.append({\n",
    "            'Mean Predicted Probability': prob_pred,\n",
    "            'Fraction of Positives': prob_true,\n",
    "            'Score': score_name,\n",
    "            'Slope': slope,\n",
    "            'Intercept': intercept,\n",
    "            'Counts': counts\n",
    "        })\n",
    "\n",
    "    df_calibration = pd.concat([pd.DataFrame(data) for data in calibration_results]).reset_index(drop=True)\n",
    "    # df_calibration\n",
    "\n",
    "    \"\"\"\n",
    "    plotting\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(data=df_calibration, \n",
    "                x='Mean Predicted Probability', \n",
    "                y='Fraction of Positives', \n",
    "                hue='Score', \n",
    "                markers=True, \n",
    "                marker='o', \n",
    "                style=None, \n",
    "                dashes=False,\n",
    "                palette=color_map)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "\n",
    "    for i, score_name in enumerate(df_calibration['Score'].unique()):\n",
    "        subset = df_calibration[df_calibration['Score'] == score_name]\n",
    "        slope = subset['Slope'].values[0]\n",
    "        intercept = subset['Intercept'].values[0]\n",
    "        print(f'{score_name}: Slope={slope:.4f}, Intercept={intercept:.4f}')\n",
    "\n",
    "    plt.xlabel('Mean Predicted Probability')\n",
    "    plt.ylabel('Fraction of Positives')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    bin sizes\n",
    "    \"\"\"\n",
    "\n",
    "    df_scores_counts = {}\n",
    "    for score_name in df_calibration['Score'].unique():\n",
    "        subset = df_calibration[df_calibration['Score'] == score_name]\n",
    "        \n",
    "        table = pd.DataFrame({\n",
    "            'Mean Predicted Probability': subset['Mean Predicted Probability'],\n",
    "            'Fraction of Positives': subset['Fraction of Positives'],\n",
    "            'Counts': subset['Counts'],\n",
    "        })\n",
    "\n",
    "        table['Score'] = score_name\n",
    "\n",
    "        df_scores_counts[score_name] = table\n",
    "\n",
    "    df_combined = pd.concat(df_scores_counts.values(), ignore_index=True)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    export\n",
    "    \"\"\"\n",
    "\n",
    "    df_calibration.to_csv(f'{path}_calibration.csv', index=False)\n",
    "    df_combined.to_csv(f'{path}_calibration_counts.csv', index=False)\n",
    "    plt.savefig(f'{path}_calibration.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrimination(df:pd.DataFrame, score_columns:list, outcome_columns:list, score_names:list, test_split:float, path:str):\n",
    "\n",
    "    \"\"\"\n",
    "    data | AUROC\n",
    "    \"\"\"\n",
    "\n",
    "    roc_results = []\n",
    "\n",
    "    for score, outcome, score_name in zip(score_columns, outcome_columns, score_names):\n",
    "        \n",
    "        categorical_column = []\n",
    "        if score in categorical_columns:\n",
    "            categorical_column = [score]\n",
    "            \n",
    "        df_test = analysis_utils.get_test_data(\n",
    "            df=df, \n",
    "            score_column=score, \n",
    "            outcome_column=outcome, \n",
    "            test_size=test_split, \n",
    "            categorical_columns=categorical_column\n",
    "            )  \n",
    "        \n",
    "        y_true = df_test[outcome]\n",
    "        y_score = df_test[[f'{score}_probability']]\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        auc = roc_auc_score(y_true, y_score)\n",
    "        \n",
    "        roc_results.append({\n",
    "            'False Positive Rate': fpr,\n",
    "            'True Positive Rate': tpr,\n",
    "            'Score': score_name,\n",
    "            'AUC': auc,\n",
    "        })\n",
    "\n",
    "    df_roc = pd.concat([pd.DataFrame(data) for data in roc_results]).reset_index(drop=True)\n",
    "    # df_roc\n",
    "\n",
    "    \"\"\"\n",
    "    plotting | AUROC\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.lineplot(data=df_roc, \n",
    "                    x='False Positive Rate', \n",
    "                    y='True Positive Rate', \n",
    "                    hue='Score', \n",
    "                    # markers=True, \n",
    "                    # marker='o', \n",
    "                    # style=None, \n",
    "                    dashes=False,\n",
    "                    palette=color_map)\n",
    "\n",
    "    # reference: https://matplotlib.org/2.0.2/users/legend_guide.html\n",
    "    scores_auc = df_roc[['Score', 'AUC']].drop_duplicates().set_index('Score')\n",
    "    auc_dict = scores_auc.to_dict()\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()    \n",
    "    new_labels = [f\"{label} (AUC = {auc_dict['AUC'][label]:.4f})\" for label in labels]\n",
    "    plt.legend(handles, new_labels)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # plt.title('ROC Curve')\n",
    "    # plt.legend(title='Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    export | AUROC (Figure)\n",
    "    \"\"\"\n",
    "\n",
    "    plt.savefig(f'{path}_AUROC.png')\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    data | AUPRC\n",
    "    \"\"\"\n",
    "\n",
    "    prc_results = []\n",
    "\n",
    "    for score, outcome, score_name in zip(score_columns, outcome_columns, score_names):\n",
    "\n",
    "        df_test = analysis_utils.get_test_data(\n",
    "            df=df, \n",
    "            score_column=score, \n",
    "            outcome_column=outcome, \n",
    "            test_size=test_split\n",
    "            )\n",
    "        \n",
    "        y_true = df_test[outcome]\n",
    "        y_score = df_test[[f'{score}_probability']]\n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        auc_pr = average_precision_score(y_true, y_score)\n",
    "\n",
    "        baseline = sum(df_test[outcome]) / len(df_test[outcome])\n",
    "        \n",
    "        prc_results.append({\n",
    "            'Recall': recall,\n",
    "            'Precision': precision,\n",
    "            'Score': score_name,\n",
    "            'AUPRC': auc_pr,\n",
    "            'Baseline': baseline\n",
    "        })\n",
    "\n",
    "    df_prc = pd.concat([pd.DataFrame(data) for data in prc_results]).reset_index(drop=True)\n",
    "    # df_prc\n",
    "\n",
    "    \"\"\"\n",
    "    plotting | AUPRC\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.lineplot(data=df_prc, \n",
    "                    x='Recall', \n",
    "                    y='Precision', \n",
    "                    hue='Score', \n",
    "                    dashes=False,\n",
    "                    palette=color_map)\n",
    "\n",
    "    scores_auprc = df_prc[['Score', 'AUPRC']].drop_duplicates().set_index('Score')['AUPRC'].to_dict()\n",
    "    scores_baseline = df_prc[['Score', 'Baseline']].drop_duplicates().set_index('Score')['Baseline'].to_dict()\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    new_labels = [f'{label} (AUC = {scores_auprc[label]:.4f} | Baseline = {scores_baseline[label]:.4f})' for label in labels]\n",
    "    plt.legend(handles, new_labels)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # plt.title('Precision-Recall Curve')\n",
    "    # plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    export | AUPRC (Figure)\n",
    "    \"\"\"\n",
    "\n",
    "    plt.savefig(f'{path}_AUPRC.png')\n",
    "\n",
    "    \"\"\"\n",
    "    export\n",
    "    \"\"\"\n",
    "\n",
    "    df_roc.to_csv(f'{path}_AUROC.csv', index=False)\n",
    "    df_prc.to_csv(f'{path}_AUPRC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(df:pd.DataFrame, score_columns:list, outcome_columns:list, score_names:list, test_split:float, path:str):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=len(score_columns), ncols=1, figsize=(10, 6 * len(score_columns)), sharex=True, sharey=True)\n",
    "\n",
    "    for i, (score, outcome, score_name) in enumerate(zip(score_columns, outcome_columns, score_names)):\n",
    "\n",
    "        \"\"\"\n",
    "        data\n",
    "        \"\"\"\n",
    "\n",
    "        df_test = analysis_utils.get_test_data(\n",
    "            df=df, \n",
    "            score_column=score, \n",
    "            outcome_column=outcome, \n",
    "            test_size=test_split\n",
    "            )\n",
    "\n",
    "        df_test.drop(columns=score, inplace=True)\n",
    "        df_test.rename(columns={f'{score}_probability': f'{score_name}'}, inplace=True)\n",
    "        \n",
    "        df_dca = dca(data=df_test, outcome=outcome, modelnames=[score_name], thresholds=np.arange(0, 0.10, 0.01))\n",
    "        # df_dca\n",
    "\n",
    "        \"\"\"\n",
    "        plotting\n",
    "        \"\"\"\n",
    "        \n",
    "        sns.lineplot(data=df_dca, x='threshold', y='net_benefit', hue='model', palette=color_map, ax=axes[i])\n",
    "        axes[i].set_xlabel('Threshold')\n",
    "        axes[i].set_ylabel('Net Benefit')\n",
    "        axes[i].set_title(f'{score_name}')\n",
    "        axes[i].set_ylim([-0.01, 0.02])\n",
    "        axes[i].legend(title='')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    export\n",
    "    \"\"\"\n",
    "\n",
    "    df_dca.to_csv(f'{path}_DCA.csv', index=False)\n",
    "    plt.savefig(f'{path}_DCA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_by_score(df:pd.DataFrame, score_columns: list, outcome_columns: list, score_names: list, test_split:float, path: str):\n",
    "    \n",
    "    for score, score_name in zip(score_columns, score_names):\n",
    "\n",
    "        df_proba = df.groupby(score).agg(\n",
    "            probability=(f'{score}_probability', 'mean'),\n",
    "            probability_CI_lower=(f'{score}_probability_CI_lower', 'mean'),\n",
    "            probability_CI_upper=(f'{score}_probability_CI_upper', 'mean')\n",
    "        ).reset_index()\n",
    "\n",
    "        df_proba = df_proba.sort_values(by=score)\n",
    "        df_proba = df_proba.rename({\n",
    "            score: score_name,\n",
    "            f'{score}_probability': f'{score_name} Probability', \n",
    "            f'{score}_probability_CI_lower': f'{score_name} Probability CI (upper)', \n",
    "            f'{score}_probability_CI_upper': f'{score_name} Probability CI (lower)'\n",
    "        })\n",
    "\n",
    "        df_proba.to_csv(f'{path}_{score}_probabilities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df:pd.DataFrame, score_columns: list, outcome_columns: list, score_names: list, outcome_names: list, date_time_column:str, timeframe:str, test_split:float, path: str):\n",
    "\n",
    "    functions = {\n",
    "        'BS & BSS': get_performance,\n",
    "        'Calibration': get_calibration,\n",
    "        'Discrimination': get_discrimination,\n",
    "        'Clinical Value': get_value,\n",
    "        'Score Probability': get_proba_by_score\n",
    "    }\n",
    "    \n",
    "    for func_name, func in functions.items():\n",
    "        print(f'Started {func_name} for {score_names} and {outcome_names}')\n",
    "        with suppress_prints():\n",
    "            if func_name == 'BS & BSS':\n",
    "                func(df=df, score_columns=score_columns, outcome_columns=outcome_columns, score_names=score_names, outcome_names=outcome_names, test_split=test_split, path=path)\n",
    "            else:\n",
    "                func(df=df, score_columns=score_columns, outcome_columns=outcome_columns, score_names=score_names, test_split=test_split, path=path)\n",
    "                \n",
    "        print(f'Completed {func_name} for {score_names} and {outcome_names}')\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'figures/scores/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_cohort_validation] + list(subgroups.values())\n",
    "df_name_list = ['cohort'] + list(subgroups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in df_name_list:\n",
    "    os.makedirs(main_path + dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, df_name in zip(df_list, df_name_list):\n",
    "\n",
    "    print(f'Started {df_name}')\n",
    "\n",
    "    get_metrics(\n",
    "        df = df,\n",
    "        score_columns = ['RCRI_original', 'RCRI_recalibrated_converted', 'expanded_RCRI_converted'], \n",
    "        outcome_columns = ['MACE_30_days', 'MACE_30_days', 'MACE_30_days'], \n",
    "        score_names = ['RCRI (original)', 'RCRI (recalibrated, converted)', 'RCRI (expanded, converted)'], \n",
    "        outcome_names = ['MACE', 'MACE', 'MACE'], \n",
    "        date_time_column = 'op_date_time',\n",
    "        timeframe = '1Y',\n",
    "        test_split = train_test_split,\n",
    "        path = main_path + df_name + '/' + 'RCRI-versions'\n",
    "    )\n",
    "\n",
    "    get_metrics(\n",
    "        df = df,\n",
    "        score_columns=['CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted'], \n",
    "        outcome_columns=['stroke_30_days', 'stroke_30_days', 'stroke_30_days'], \n",
    "        score_names=['CHA2DS2-VASc (original)', 'CHA2DS2-VASc (recalibrated, converted)', 'CHA2DS2-VASc (expanded, converted)'], \n",
    "        outcome_names=['Stroke', 'Stroke', 'Stroke'], \n",
    "        date_time_column = 'op_date_time',\n",
    "        timeframe = '1Y',\n",
    "        test_split = train_test_split,\n",
    "        path = main_path + df_name + '/' + 'CHA-versions'\n",
    "    )\n",
    "\n",
    "    get_metrics(\n",
    "        df = df,\n",
    "        score_columns = ['elixhauser_van_walraven', 'elixhauser_recalibrated_converted'], \n",
    "        outcome_columns = ['in_hospital_death', 'in_hospital_death', 'in_hospital_death'], \n",
    "        score_names = ['Elixhauser (van Walraven)', 'Elixhauser (recalibrated, converted)'], \n",
    "        outcome_names = ['In-Hospital Mortality', 'In-Hospital Mortality', 'In-Hospital Mortality'], \n",
    "        date_time_column = 'op_date_time',\n",
    "        timeframe = '3Y',\n",
    "        test_split = train_test_split,\n",
    "        path = main_path + df_name + '/' + 'Elixhauser-versions'\n",
    "    )\n",
    "\n",
    "    get_metrics(\n",
    "        df = df,\n",
    "        score_columns = ['RCRI_original', 'CHA2DS2_VASc_original', 'elixhauser_van_walraven'], \n",
    "        outcome_columns = ['MACE_30_days', 'stroke_30_days', 'in_hospital_death'], \n",
    "        score_names = ['RCRI (original)', 'CHA2DS2-VASc (original)', 'Elixhauser (van Walraven)'], \n",
    "        outcome_names = ['MACE', 'Stroke', 'In-Hospital Mortality'], \n",
    "        date_time_column = 'op_date_time',\n",
    "        timeframe = '1Y',\n",
    "        test_split = train_test_split,\n",
    "        path = main_path + df_name + '/' + 'originals'\n",
    "    )\n",
    "\n",
    "    print(f'Completed {df_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_files = [\n",
    "    'figures/scores/cohort/originals_RCRI_original_probabilities.csv',\n",
    "    'figures/scores/cohort/originals_CHA2DS2_VASc_original_probabilities.csv',\n",
    "    'figures/scores/cohort/originals_elixhauser_van_walraven_probabilities.csv'\n",
    "]\n",
    "\n",
    "score_names = [\n",
    "    'RCRI (original)', \n",
    "    'CHA2DS2-VASc (original)', \n",
    "    'Elixhauser (van Walraven)'\n",
    "]\n",
    "\n",
    "original_score_columns = [\n",
    "    'RCRI_original', \n",
    "    'CHA2DS2_VASc_original', \n",
    "    'elixhauser_van_walraven'\n",
    "]\n",
    "\n",
    "CHA_score_files = [\n",
    "    'figures/scores/cohort/originals_CHA2DS2_VASc_original_probabilities.csv',\n",
    "    'figures/scores/cohort/CHA-versions_CHA2DS2_VASc_recalibrated_converted_probabilities.csv',\n",
    "    'figures/scores/cohort/CHA-versions_expanded_CHA2DS2_VASc_converted_probabilities.csv'\n",
    "]\n",
    "\n",
    "CHA_score_names = [\n",
    "    'CHA2DS2-VASc (original)', \n",
    "    'CHA2DS2-VASc (recalibrated, converted)', \n",
    "    'CHA2DS2-VASc (expanded, converted)'\n",
    "]\n",
    "\n",
    "CHA_column_names = [\n",
    "    'CHA2DS2_VASc_original', \n",
    "    'CHA2DS2_VASc_recalibrated_converted', \n",
    "    'expanded_CHA2DS2_VASc_converted'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(score_files), ncols=1, figsize=(10, len(score_files) * 4))\n",
    "\n",
    "for idx, (score_file, score_name, score_column) in enumerate(zip(score_files, score_names, original_score_columns)):\n",
    "    df = pd.read_csv(score_file)\n",
    "    \n",
    "    color = color_map.get(score_name, 'gray')\n",
    "    \n",
    "    ax = axes[idx]\n",
    "\n",
    "    ax.errorbar(df[score_column], df['probability'], \n",
    "                yerr=[df['probability'] - df['probability_CI_lower'], \n",
    "                      df['probability_CI_upper'] - df['probability']],\n",
    "                fmt='o', color=color, capsize=5, label=score_name)\n",
    "    \n",
    "    # ax.set_title(f\"{score_name} Probability vs Score\")\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Probability for Outcome')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHA Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(score_files), ncols=1, figsize=(10, len(score_files) * 4))\n",
    "\n",
    "for idx, (score_file, score_name, score_column) in enumerate(zip(CHA_score_files, CHA_score_names, CHA_column_names)):\n",
    "    df = pd.read_csv(score_file)\n",
    "    \n",
    "    color = color_map.get(score_name, 'gray')\n",
    "    \n",
    "    ax = axes[idx]\n",
    "\n",
    "    ax.errorbar(df[score_column], df['probability'], \n",
    "                yerr=[df['probability'] - df['probability_CI_lower'], \n",
    "                      df['probability_CI_upper'] - df['probability']],\n",
    "                fmt='o', color=color, capsize=5, label=score_name)\n",
    "    \n",
    "    # ax.set_title(f\"{score_name} Probability vs Score\")\n",
    "    ax.set_xlabel('Score')\n",
    "    ax.set_ylabel('Probability for Outcome')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for score_file, score_name, score_column in zip(CHA_score_files, CHA_score_names, CHA_column_names):\n",
    "    \n",
    "    df = pd.read_csv(score_file)\n",
    "    \n",
    "    color = color_map.get(score_name, 'gray') \n",
    "    \n",
    "    plt.errorbar(df[score_column], df['probability'], \n",
    "                 yerr=[df['probability'] - df['probability_CI_lower'], \n",
    "                       df['probability_CI_upper'] - df['probability']],\n",
    "                 fmt='o', color=color, capsize=5, label=score_name)\n",
    "\n",
    "# plt.title(\"Probability vs Score for Multiple Risk Scores\")\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Probability for Outcome')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCRI_variables = [\n",
    "    'elevated_risk_surgery', 'MI_history', 'congestive_heart_failure_elixhauser', \n",
    "    'CD_history', 'prior_insulin', 'prior_creatinine'\n",
    "    ]\n",
    "\n",
    "MACE_outcome = 'MACE_30_days'\n",
    "\n",
    "selected_MACE_features_columns = ['O42_ICD_history', 'J35_ICD_history', 'O09_ICD_history', 'J34_ICD_history', 'O26_ICD_history', 'C69_ICD_history', 'D25_ICD_history', 'M23_ICD_history', 'H33_ICD_history', 'K35_ICD_history', 'M75_ICD_history', 'M51_ICD_history', 'J32_ICD_history', 'Z37_ICD_history', 'O99_ICD_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHA_variables = [\n",
    "    'female_sex', 'congestive_heart_failure_elixhauser', 'hypertension_uncomplicated_elixhauser', \n",
    "    'hypertension_complicated_elixhauser', 'diabetes_uncomplicated_elixhauser', 'diabetes_complicated_elixhauser', \n",
    "    'vascular_disease_history', 'STT_history', 'age_below_65', 'age_between_65_and_74', 'age_above_74']\n",
    "\n",
    "stroke_outcome = 'stroke_30_days'\n",
    "\n",
    "selected_stroke_features_columns = ['Z37_ICD_history', 'O42_ICD_history', 'J34_ICD_history', 'C44_ICD_history', 'J35_ICD_history', 'O26_ICD_history', 'C43_ICD_history', 'H33_ICD_history', 'M23_ICD_history', 'O09_ICD_history', 'C69_ICD_history', 'K35_ICD_history', 'H25_ICD_history', 'M51_ICD_history', 'I63_ICD_history']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original weights, no oversampling, no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "variables = RCRI_variables #+ selected_MACE_features_columns\n",
    "outcome = MACE_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "X_train, X_test, y_train, y_test = ml_utils.preprocessing(\n",
    "    df=df_cohort_validation, \n",
    "    variables=variables, \n",
    "    outcome=outcome, \n",
    "    scale=False, \n",
    "    resample=False, \n",
    "    test_size=train_test_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare, train, and evaluate model\n",
    " \n",
    "class_weights = ml_utils.get_class_weights(y_train=y_train)\n",
    "\n",
    "model, criterion, optimizer = ml_utils.get_model(\n",
    "    features=len(variables), \n",
    "    class_weights_tensor=class_weights, \n",
    "    selected_model=ml_utils.Model.CUSTOM\n",
    "    )\n",
    "\n",
    "ml_utils.train(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    model=model, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    epochs=800\n",
    "    )\n",
    "\n",
    "ml_utils.evaluate(\n",
    "    model=model, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original weights, with oversampling, no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "variables = RCRI_variables\n",
    "outcome = MACE_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "X_train, X_test, y_train, y_test = ml_utils.preprocessing(\n",
    "    df=df_cohort_validation, \n",
    "    variables=variables, \n",
    "    outcome=outcome, \n",
    "    scale=False, \n",
    "    resample=True, \n",
    "    test_size=train_test_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare, train, and evaluate model\n",
    " \n",
    "class_weights = ml_utils.get_class_weights(y_train=y_train)\n",
    "\n",
    "model, criterion, optimizer = ml_utils.get_model(\n",
    "    features=len(variables), \n",
    "    class_weights_tensor=class_weights, \n",
    "    selected_model=ml_utils.Model.CUSTOM\n",
    "    )\n",
    "\n",
    "ml_utils.train(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    model=model, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    epochs=800\n",
    "    )\n",
    "\n",
    "ml_utils.evaluate(\n",
    "    model=model, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original weights, no oversampling, with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "variables = RCRI_variables\n",
    "outcome = MACE_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "X_train, X_test, y_train, y_test = ml_utils.preprocessing(\n",
    "    df=df_cohort_validation, \n",
    "    variables=variables, \n",
    "    outcome=outcome, \n",
    "    scale=True, \n",
    "    resample=False, \n",
    "    test_size=train_test_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare, train, and evaluate model\n",
    " \n",
    "class_weights = ml_utils.get_class_weights(y_train=y_train)\n",
    "\n",
    "model, criterion, optimizer = ml_utils.get_model(\n",
    "    features=len(variables), \n",
    "    class_weights_tensor=class_weights, \n",
    "    selected_model=ml_utils.Model.CUSTOM\n",
    "    )\n",
    "\n",
    "ml_utils.train(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    model=model, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    epochs=800\n",
    "    )\n",
    "\n",
    "ml_utils.evaluate(\n",
    "    model=model, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original weights, with oversampling, with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "variables = RCRI_variables\n",
    "outcome = MACE_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "X_train, X_test, y_train, y_test = ml_utils.preprocessing(\n",
    "    df=df_cohort_validation, \n",
    "    variables=variables, \n",
    "    outcome=outcome, \n",
    "    scale=True, \n",
    "    resample=True, \n",
    "    test_size=train_test_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare, train, and evaluate model\n",
    " \n",
    "class_weights = ml_utils.get_class_weights(y_train=y_train)\n",
    "\n",
    "model, criterion, optimizer = ml_utils.get_model(\n",
    "    features=len(variables), \n",
    "    class_weights_tensor=class_weights, \n",
    "    selected_model=ml_utils.Model.CUSTOM\n",
    "    )\n",
    "\n",
    "ml_utils.train(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    model=model, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    epochs=800\n",
    "    )\n",
    "\n",
    "ml_utils.evaluate(\n",
    "    model=model, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### expanded weights, no oversampling, no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "variables = RCRI_variables + selected_MACE_features_columns\n",
    "outcome = MACE_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "X_train, X_test, y_train, y_test = ml_utils.preprocessing(\n",
    "    df=df_cohort_validation, \n",
    "    variables=variables, \n",
    "    outcome=outcome, \n",
    "    scale=False, \n",
    "    resample=False, \n",
    "    test_size=train_test_split\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare, train, and evaluate model\n",
    " \n",
    "class_weights = ml_utils.get_class_weights(y_train=y_train)\n",
    "\n",
    "model, criterion, optimizer = ml_utils.get_model(\n",
    "    features=len(variables), \n",
    "    class_weights_tensor=class_weights, \n",
    "    selected_model=ml_utils.Model.CUSTOM\n",
    "    )\n",
    "\n",
    "ml_utils.train(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    model=model, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    epochs=800\n",
    "    )\n",
    "\n",
    "ml_utils.evaluate(\n",
    "    model=model, \n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all models # reference: https://pycaret.gitbook.io/docs/get-started/functions/others#models\n",
    "from pycaret.datasets import get_data\n",
    "data = get_data('diabetes')\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data, target = 'Class variable')\n",
    "list(models(internal = True)['Reference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### expanded MACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data = df_cohort_validation[\n",
    "    RCRI_variables + selected_MACE_features_columns + [MACE_outcome]\n",
    "    ].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and test models\n",
    "autoML_model = ml_utils.get_autoML(\n",
    "    data=data, \n",
    "    target=MACE_outcome\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Existing variables\n",
    "data_vars = list(df_cohort_validation.columns)\n",
    "columns_to_remove = [\n",
    "    'pat_id', 'case_id', 'admission_date_time', 'discharge_date_time', 'ops_code', 'op_date_time', 'birth_date', \n",
    "    'in_hospital_death', 'MACE_30_days', 'stroke_30_days',\n",
    "    'elixhauser_van_walraven', 'elixhauser_recalibrated', 'expanded_elixhauser', \n",
    "    'elixhauser_recalibrated_converted', 'expanded_elixhauser_converted', \n",
    "    'RCRI_original', 'RCRI_recalibrated', 'expanded_RCRI', \n",
    "    'RCRI_recalibrated_converted', 'expanded_RCRI_converted', \n",
    "    'CHA2DS2_VASc_original', 'CHA2DS2_VASc_recalibrated', 'expanded_CHA2DS2_VASc', \n",
    "    'CHA2DS2_VASc_recalibrated_converted', 'expanded_CHA2DS2_VASc_converted',\n",
    "\n",
    "    'RCRI_original_probability',\n",
    "    'RCRI_original_probability_CI_lower',\n",
    "    'RCRI_original_probability_CI_upper',\n",
    "    'RCRI_recalibrated_converted_probability',\n",
    "    'RCRI_recalibrated_converted_probability_CI_lower',\n",
    "    'RCRI_recalibrated_converted_probability_CI_upper',\n",
    "    'expanded_RCRI_converted_probability',\n",
    "    'expanded_RCRI_converted_probability_CI_lower',\n",
    "    'expanded_RCRI_converted_probability_CI_upper',\n",
    "    'CHA2DS2_VASc_original_probability',\n",
    "    'CHA2DS2_VASc_original_probability_CI_lower',\n",
    "    'CHA2DS2_VASc_original_probability_CI_upper',\n",
    "    'CHA2DS2_VASc_recalibrated_converted_probability',\n",
    "    'CHA2DS2_VASc_recalibrated_converted_probability_CI_lower',\n",
    "    'CHA2DS2_VASc_recalibrated_converted_probability_CI_upper',\n",
    "    'expanded_CHA2DS2_VASc_converted_probability',\n",
    "    'expanded_CHA2DS2_VASc_converted_probability_CI_lower',\n",
    "    'expanded_CHA2DS2_VASc_converted_probability_CI_upper',\n",
    "    'elixhauser_van_walraven_probability',\n",
    "    'elixhauser_van_walraven_probability_CI_lower',\n",
    "    'elixhauser_van_walraven_probability_CI_upper',\n",
    "    'elixhauser_recalibrated_converted_probability',\n",
    "    'elixhauser_recalibrated_converted_probability_CI_lower',\n",
    "    'elixhauser_recalibrated_converted_probability_CI_upper',\n",
    "    'expanded_elixhauser_converted_probability',\n",
    "    'expanded_elixhauser_converted_probability_CI_lower',\n",
    "    'expanded_elixhauser_converted_probability_CI_upper',\n",
    "\n",
    "    'female',\n",
    "    'male',\n",
    "    'campus'\n",
    "]\n",
    "\n",
    "all_predictors = [col for col in data_vars if col not in columns_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(all_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data = df_cohort_validation[\n",
    "    all_predictors + [MACE_outcome]\n",
    "    ].copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and test models\n",
    "autoML_model = ml_utils.get_autoML(\n",
    "    data=data, \n",
    "    target=MACE_outcome\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here data that was excluded will again be derived for the purpose of this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_patients = df_cohort_validation.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, error = extraction_utils.connect_impala(\n",
    "    remote_hostname='hdl-edge01.charite.de', \n",
    "    username='nokr10'\n",
    "    ) # connect to HDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_date = \"CAST( `_hdl_loadstamp` AS DATE) <= '2024-09-05'\" # set for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = (\n",
    "    'c_var_name IN (\"BEH_ANAE_ASA_STATUS\", \"Risiko_ASA\", \"Behandlung_Anae_Praemed_ASA_Status\", \"Praemedikation_ASA_Status\") OR ' # ASA status\n",
    "    'c_var_name IN (\"Patient_Gewicht\", \"Behandlung_Gewicht\", \"Behandlung_Gewicht_Aufnahme\", \"CO_klinStatus_Behandlung_Patient_Aufnahme_Gewicht_\", \"CO_Patient_Aufnahme_Gewicht\") OR ' # weight\n",
    "    'c_var_name IN (\"Patient_Groesse\", \"Praemedikation_Groesse\", \"CO_klinStatus_Behandlung_Patient_Aufnahme_Groesse_\", \"CO_Patient_Aufnahme_Groesse\")' # height\n",
    ")\n",
    "\n",
    "df_hdl_copra_hierarchy = extraction_utils.get_impala_df(\n",
    "    database='db_corror_prepared', \n",
    "    table='it_copra6_hierarchy_v2', \n",
    "    conn=conn, \n",
    "    where=where + ' AND ' + extraction_date\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hierarchy = utils.extract_df_data(\n",
    "    df_hdl_copra_hierarchy, \n",
    "    col_dict={\n",
    "        'c_falnr':'case_id', \n",
    "        'c_var_name':'variable', \n",
    "        'c_value':'value', \n",
    "        'c_var_timestamp':'date_time'\n",
    "        },\n",
    "    remove_prefix=False,\n",
    "    drop=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_hierarchy = df_hierarchy.astype({\n",
    "    # 'case_id': str,\n",
    "    # 'variable': str,\n",
    "    # 'value': ...,\n",
    "})\n",
    "\n",
    "for column in ['date_time']:\n",
    "    df_hierarchy[f'{column}'] = pd.to_datetime(df_hierarchy[f'{column}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract by priority\n",
    "df_weight = utils.extract_by_priority(\n",
    "    df=df_hierarchy, \n",
    "    column='variable', \n",
    "    priority_order=[\n",
    "        'Patient_Gewicht', 'Praemedikation_Gewicht', 'Behandlung_Gewicht', 'Behandlung_Gewicht_Aufnahme', \n",
    "        'CO_klinStatus_Behandlung_Patient_Aufnahme_Gewicht_', 'CO_Patient_Aufnahme_Gewicht'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.handle_duplicates(\n",
    "    df=df_weight, \n",
    "    column='case_id', \n",
    "    drop_duplicates=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_weight.rename(columns={'value': 'weight'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_weight = df_weight.astype({\n",
    "    # 'case_id': str,\n",
    "    'weight': float\n",
    "})\n",
    "\n",
    "for column in ['date_time']:\n",
    "    df_weight[f'{column}'] = pd.to_datetime(df_weight[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort_patients = pd.merge(df_cohort_patients, df_weight[['case_id', 'weight']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract by priority\n",
    "df_height = utils.extract_by_priority(\n",
    "    df=df_hierarchy, \n",
    "    column='variable', \n",
    "    priority_order=[\n",
    "        'Patient_Groesse', 'Praemedikation_Groesse', 'CO_klinStatus_Behandlung_Patient_Aufnahme_Groesse_', \n",
    "        'CO_Patient_Aufnahme_Groesse'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.handle_duplicates(\n",
    "    df=df_height, \n",
    "    column='case_id', \n",
    "    drop_duplicates=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_height.rename(columns={'value': 'height'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_height = df_height.astype({\n",
    "    # 'case_id': str,\n",
    "    'height': float\n",
    "})\n",
    "\n",
    "for column in ['date_time']:\n",
    "    df_height[f'{column}'] = pd.to_datetime(df_height[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort_patients = pd.merge(df_cohort_patients, df_height[['case_id', 'height']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmi = df_cohort_patients[['case_id', 'weight', 'height']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmi['bmi'] = df_bmi['weight'] / ((df_bmi['height'] * 0.01) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_bmi = df_bmi.astype({\n",
    "    # 'case_id': str,\n",
    "    'bmi': float\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort_patients = pd.merge(df_cohort_patients, df_bmi[['case_id', 'bmi']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ASA Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract by priority\n",
    "df_asa_status = utils.extract_by_priority(\n",
    "    df=df_hierarchy, \n",
    "    column='variable', \n",
    "    priority_order=[\n",
    "        'BEH_ANAE_ASA_STATUS', 'Risiko_ASA', 'Behandlung_Anae_Praemed_ASA_Status', \n",
    "        'Praemedikation_ASA_Status'\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.handle_duplicates(\n",
    "    df=df_asa_status, \n",
    "    column='case_id', \n",
    "    drop_duplicates=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df_asa_status.rename(columns={'value': 'asa_status'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all numbers\n",
    "\n",
    "def extract_number(value):\n",
    "    number = ''.join(filter(str.isdigit, str(value)))\n",
    "    return int(number) if number else np.nan\n",
    "\n",
    "df_asa_status['asa_status'] = df_asa_status['asa_status'].apply(extract_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asa_status_cleaned = df_asa_status.dropna(subset=['asa_status'])\n",
    "utils.get_amount_removed_rows(\n",
    "    initial=df_asa_status, \n",
    "    new=df_asa_status_cleaned\n",
    "    )\n",
    "df_asa_status = df_asa_status_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data types\n",
    "\n",
    "df_asa_status = df_asa_status.astype({\n",
    "    # 'case_id': str,\n",
    "    'asa_status': int\n",
    "})\n",
    "\n",
    "for column in ['date_time']:\n",
    "    df_asa_status[f'{column}'] = pd.to_datetime(df_asa_status[f'{column}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with cohort\n",
    "df_cohort_patients = pd.merge(df_cohort_patients, df_asa_status[['case_id', 'asa_status']], on='case_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_patients = utils.clean_values(\n",
    "    df=df_cohort_patients, \n",
    "    reference_values='data/reference-values.csv', \n",
    "    drop_rows=False # only set to missing\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(row, columns):\n",
    "    return ', '.join([col for col in columns if row[col] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_patients.rename(\n",
    "    columns={\n",
    "        'ambulatory': 'Ambulatory', \n",
    "        'inpatient': 'Inpatient', \n",
    "    }, \n",
    "    inplace=True)\n",
    "admission_types = ['Ambulatory', 'Inpatient', 'SDA']\n",
    "df_cohort_patients['admission_type'] = df_cohort_patients.apply(combine_columns, axis=1, columns=admission_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_patients.rename(\n",
    "    columns={\n",
    "        'MACE_30_days': 'MACE', \n",
    "        'stroke_30_days': 'Stroke', \n",
    "        'in_hospital_death': 'Death'\n",
    "    }, \n",
    "    inplace=True)\n",
    "admission_types = ['MACE', 'Stroke', 'Death']\n",
    "df_cohort_patients['outcome'] = df_cohort_patients.apply(combine_columns, axis=1, columns=admission_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_patients['campus'] = df_cohort_patients['campus'].replace({\n",
    "    'M': 'Mitte',\n",
    "    'S': 'Steglitz',\n",
    "    'W': 'Wedding'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_cohort_patients.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_columns = ['age_during_op', 'female_sex', 'bmi', 'asa_status', 'elixhauser_van_walraven', 'admission_type', 'outcome', 'campus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cohort_patients[cleaned_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_cleaned.columns.tolist()\n",
    "categorical = ['asa_status', 'admission_type', 'outcome', 'campus', 'female_sex']\n",
    "groupby = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = ['age_during_op', 'bmi', 'elixhauser_van_walraven']\n",
    "rename = {\n",
    "    'age_during_op': 'Patient age',\n",
    "    'female_sex': 'Female patient',\n",
    "    'bmi': 'BMI',\n",
    "    'asa_status': 'ASA status',\n",
    "    'elixhauser_van_walraven': 'Elixhauser index',\n",
    "    'admission_type': 'Admission type',\n",
    "    'outcome': 'Outcome',\n",
    "    'campus': 'Campus'\n",
    "}\n",
    "decimals = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tableOne = TableOne(\n",
    "    data=df_cleaned, \n",
    "    columns=columns, \n",
    "    categorical=categorical, \n",
    "    groupby=groupby, \n",
    "    min_max=min_max, \n",
    "    rename=rename, \n",
    "    decimals=decimals, \n",
    "    # pval=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tableOne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_death_count = df_cohort_validation['in_hospital_death'].sum()\n",
    "df_elevated_risk = df_cohort_validation[\n",
    "    df_cohort_validation['elevated_risk_surgery'] \\\n",
    "    == 1]\n",
    "risk_death_count = df_elevated_risk['in_hospital_death'] \\\n",
    "    .sum()\n",
    "\n",
    "total_death_percentage = (total_death_count / len(df_cohort_validation))\n",
    "risk_death_percentage = \\\n",
    "    (risk_death_count / len(df_elevated_risk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_death_percentage * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_death_percentage * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
